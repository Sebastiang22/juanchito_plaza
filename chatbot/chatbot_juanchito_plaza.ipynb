{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langfuse\n",
      "  Downloading langfuse-2.52.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting anyio<5.0.0,>=4.4.0 (from langfuse)\n",
      "  Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting backoff>=1.10.0 (from langfuse)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting httpx<1.0,>=0.15.4 (from langfuse)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting idna<4.0,>=3.7 (from langfuse)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging<25.0,>=23.2 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langfuse) (24.1)\n",
      "Collecting pydantic<3.0,>=1.10.7 (from langfuse)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting wrapt<2.0,>=1.14 (from langfuse)\n",
      "  Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5.0.0,>=4.4.0->langfuse)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting certifi (from httpx<1.0,>=0.15.4->langfuse)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0,>=0.15.4->langfuse)\n",
      "  Using cached httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0,>=1.10.7->langfuse)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3.0,>=1.10.7->langfuse)\n",
      "  Using cached pydantic_core-2.23.4-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting typing-extensions>=4.6.1 (from pydantic<3.0,>=1.10.7->langfuse)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading langfuse-2.52.1-py3-none-any.whl (220 kB)\n",
      "Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Using cached pydantic_core-2.23.4-cp312-none-win_amd64.whl (1.9 MB)\n",
      "Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: wrapt, typing-extensions, sniffio, idna, h11, certifi, backoff, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, langfuse\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.6.2.post1 backoff-2.2.1 certifi-2024.8.30 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 idna-3.10 langfuse-2.52.1 pydantic-2.9.2 pydantic-core-2.23.4 sniffio-1.3.1 typing-extensions-4.12.2 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.2.39-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.10.10-cp312-cp312-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.12 (from langchain)\n",
      "  Downloading langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.136-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain) (2.9.2)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.32 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.33-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting openai<2.0.0,>=1.52.0 (from langchain_openai)\n",
      "  Downloading openai-1.52.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Using cached tiktoken-0.8.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.15.5-cp312-cp312-win_amd64.whl.metadata (63 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.12->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph)\n",
      "  Using cached msgpack-1.1.0-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.27.2)\n",
      "Collecting httpx-sse>=0.4.0 (from langgraph-sdk<0.2.0,>=0.1.32->langgraph)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.2.0,>=0.1.32->langgraph)\n",
      "  Using cached orjson-3.10.7-cp312-none-win_amd64.whl.metadata (51 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (4.6.2.post1)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.52.0->langchain_openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.52.0->langchain_openai)\n",
      "  Downloading jiter-0.6.1-cp312-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.52.0->langchain_openai)\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\n",
      "  Using cached regex-2024.9.11-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm>4->openai<2.0.0,>=1.52.0->langchain_openai) (0.4.6)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.0-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 6.8 MB/s eta 0:00:00\n",
      "Downloading langgraph-0.2.39-py3-none-any.whl (113 kB)\n",
      "Downloading langchain_openai-0.2.3-py3-none-any.whl (49 kB)\n",
      "Downloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 17.0 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.10.10-cp312-cp312-win_amd64.whl (379 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_core-0.3.12-py3-none-any.whl (407 kB)\n",
      "Using cached langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading langgraph_checkpoint-2.0.1-py3-none-any.whl (22 kB)\n",
      "Downloading langgraph_sdk-0.1.33-py3-none-any.whl (28 kB)\n",
      "Downloading langsmith-0.1.136-py3-none-any.whl (296 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Downloading openai-1.52.0-py3-none-any.whl (386 kB)\n",
      "Downloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 11.6 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached tiktoken-0.8.0-cp312-cp312-win_amd64.whl (883 kB)\n",
      "Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading jiter-0.6.1-cp312-none-win_amd64.whl (198 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
      "Using cached msgpack-1.1.0-cp312-cp312-win_amd64.whl (75 kB)\n",
      "Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Using cached orjson-3.10.7-cp312-none-win_amd64.whl (137 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached regex-2024.9.11-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading yarl-1.15.5-cp312-cp312-win_amd64.whl (85 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading propcache-0.2.0-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Installing collected packages: urllib3, tqdm, tenacity, regex, PyYAML, python-dotenv, propcache, orjson, numpy, mypy-extensions, multidict, msgpack, marshmallow, jsonpointer, jiter, httpx-sse, greenlet, frozenlist, distro, charset-normalizer, attrs, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests, jsonpatch, aiosignal, tiktoken, requests-toolbelt, pydantic-settings, openai, langgraph-sdk, dataclasses-json, aiohttp, langsmith, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain_openai, langgraph, langchain, langchain_community\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 attrs-24.2.0 charset-normalizer-3.4.0 dataclasses-json-0.6.7 distro-1.9.0 frozenlist-1.4.1 greenlet-3.1.1 httpx-sse-0.4.0 jiter-0.6.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.4 langchain-core-0.3.12 langchain-text-splitters-0.3.0 langchain_community-0.3.3 langchain_openai-0.2.3 langgraph-0.2.39 langgraph-checkpoint-2.0.1 langgraph-sdk-0.1.33 langsmith-0.1.136 marshmallow-3.23.0 msgpack-1.1.0 multidict-6.1.0 mypy-extensions-1.0.0 numpy-1.26.4 openai-1.52.0 orjson-3.10.7 propcache-0.2.0 pydantic-settings-2.6.0 python-dotenv-1.0.1 regex-2024.9.11 requests-2.32.3 requests-toolbelt-1.0.0 tenacity-9.0.0 tiktoken-0.8.0 tqdm-4.66.5 typing-inspect-0.9.0 urllib3-2.2.3 yarl-1.15.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langfuse\n",
    "%pip install langchain langgraph langchain_openai langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "sk-LgMdUJL7Lt84nkW2LIDGpYFH8kmP4WG-4uPaW3Tg3fT3BlbkFJVgFYuyAavvqmPkNy_Q2nv8pjN1xGfzIwoTScNyEXEA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    " # Carga las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "# get keys for your project from https://cloud.langfuse.com\n",
    "\n",
    "print(os.getenv(\"LANGFUSE_SECRET_KEY\"))\n",
    "print(os.getenv(\"LANGFUSE_PUBLIC_KEY\"))\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # for EU data region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # for US data region\n",
    " \n",
    "# your openai key\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))        # \"your-openai-api-key\"\n",
    "\n",
    "\n",
    "config = {\n",
    "    'user': 'root',\n",
    "    'password': '1234',\n",
    "    'host': 'localhost',\n",
    "    'port': 3306,\n",
    "    'database': 'juanchito_plaza'\n",
    "}\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objeto datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "\n",
    "class objeto_juancho_plaza(TypedDict):\n",
    "    # Primer nodo: decisión sobre la función a realizar\n",
    "    celular: str  # Número de teléfono del usuario\n",
    "    pregunta: str  # Pregunta original del usuario\n",
    "    decision: str  # Decisión sobre qué función ejecutar ('crear_usuario', 'consulta_sql', 'crear_pago')\n",
    "\n",
    "    # Nodos intermedios: detalles específicos para cada función\n",
    "    pedido: dict  # Contendrá detalles de un nuevo usuario (nombre, email, etc.)\n",
    "    \n",
    "    # Nodo final: respuesta generada\n",
    "    respuesta: str  # Respuesta final del chatbot después de procesar la solicitud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 21\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m      5\u001b[0m prompt_decision \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[0;32m      6\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m<|begin_of_text|><|start_header_id|>system<|end_header_id|> \u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m    Eres un experto en gestionar operaciones de un sistema de pedidos de comida. Tienes tres funciones principales:\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpregunta\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     19\u001b[0m )\n\u001b[1;32m---> 21\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m cadena_decision \u001b[38;5;241m=\u001b[39m prompt_decision \u001b[38;5;241m|\u001b[39m llm \u001b[38;5;241m|\u001b[39m JsonOutputParser()\n\u001b[0;32m     25\u001b[0m pregunta \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcarta\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\langchain_core\\load\\serializable.py:111\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\langchain_openai\\chat_models\\base.py:551\u001b[0m, in \u001b[0;36mBaseChatOpenAI.validate_environment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy)\n\u001b[0;32m    550\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[1;32m--> 551\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\_client.py:105\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    103\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m     )\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt_decision = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "    Eres un experto en gestionar operaciones de un sistema de pedidos de comida. Tienes tres funciones principales:\n",
    "    1. 'pedido': Usar esta función si la pregunta está relacionada platos del menú, el nombre del cliente o la direccion.\n",
    "    2. 'confirmacion': Usar esta función si la pregunta está relacionada con confirmar un pedido o si la pregunta solo es si.\n",
    "    3. 'carta': Usar esta función si la pregunta está relacionada con consultar los platos o la carta del restaurante.\n",
    "\n",
    "    No necesitas ser estricto con las palabras clave, identifica el propósito general de la pregunta para seleccionar la opción adecuada. \n",
    "    Da una opción binaria ('pedido', 'confirmacion','carta) basada en la pregunta. \n",
    "    Retorna un JSON con solo una clave 'funcion' sin preámbulo o explicación.\n",
    "\n",
    "    Pregunta a enrutar: {pregunta}\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"pregunta\"],\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "\n",
    "cadena_decision = prompt_decision | llm | JsonOutputParser()\n",
    "\n",
    "pregunta = \"carta\"\n",
    "print(cadena_decision.invoke({\"pregunta\": pregunta}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = \"\"\"\n",
    "**Menú a la carta:**\n",
    "1. **Churrasco + Chorizo** - $38.000\n",
    "    - 300 GRS. Sopas, Arroz, Jugo \n",
    "\n",
    "2. **salmon** - $38.000\n",
    "    - 180 GRS. Sopa o crema, ensalada, Arroz, Jugo \n",
    "\n",
    "3. **Mojarra Frita** - $28.000\n",
    "    - 380 GRS. Sopa, Arroz, Jugo\n",
    "\n",
    "4. **Punta de anca de cerdo** - $27.000\n",
    "    - Sopas, Arroz, Jugo, ensalada\n",
    "\n",
    "5. **Filete de Trucha** - $20.000\n",
    "    - Sopas, Arroz, Jugo, ensalada\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt_pedidos = PromptTemplate(\n",
    "    template=\"\"\" \n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "    Eres un experto en gestionar pedidos para el restaurante 'Juancho Plaza'. Tu tarea principal es recibir el pedido de los clientes y estructurarlo correctamente basándote en el menú del restaurante, el cual está dividido en dos secciones: \"A la carta\" y \"Menú ejecutivo\". El menú es el siguiente:\n",
    "\n",
    "    Menu:\n",
    "    {menu}\n",
    "\n",
    "    Tu deber es:\n",
    "    1. Recibir el pedido del cliente en lenguaje natural, incluyendo su nombre y dirección.\n",
    "    2. Identificar los elementos del pedido basándote en las opciones disponibles en el menú.\n",
    "    3. Estructurar el pedido en un formato JSON con las claves:\n",
    "    - 'nombre' (el nombre del cliente).\n",
    "    - 'direccion' (la dirección del cliente).\n",
    "    - 'a_la_carta' (una lista de los productos pedidos de la sección \"A la carta\" con su cantidad).\n",
    "    - 'menu_ejecutivo' (una lista de los productos pedidos de la sección \"Menú ejecutivo\" con su cantidad).\n",
    "    - 'extras' (una lista de extras o especificaciones adicionales si las hay).\n",
    "    - 'estado_pedido' (si todos los productos están en el menú, el estado será 'pendiente_para_confirmacion'. Si algún producto no está en el menú, el estado será 'pedido_erroneo', si falta la direccion el estado sera 'falta_direccion', si falta el nombre el estado sera 'falta_nombre').\n",
    "    - 'platos_no_encontrados' (una lista de los productos que no están en el menú, solo si hay productos que no se encuentran).\n",
    "\n",
    "    El formato de cada producto en el JSON debe ser:\n",
    "    {{\n",
    "        \"producto\": \"nombre del plato\",\n",
    "        \"cantidad\": cantidad pedida\n",
    "    }}\n",
    "\n",
    "    Si todos los platos mencionados están en el menú, responde con un JSON estructurado con el estado `pendiente para confirmacion` y el pedido. Si hay algún plato que no está en el menú, responde con el estado `pedido_erroneo` e incluye el o los platos que no están en el menú bajo la clave `platos_no_encontrados`.\n",
    "\n",
    "    Solo responde con el JSON del pedido, sin agregar ninguna explicación adicional.\n",
    "    \n",
    "    Pedido del cliente: {pregunta}\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"menu\", \"pregunta\"],\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "cadena_pedidos = prompt_pedidos | llm | JsonOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nombre': 'Mister Alex',\n",
       " 'direccion': 'calle 12 #4 01',\n",
       " 'a_la_carta': [{'producto': 'salmon', 'cantidad': 1}],\n",
       " 'menu_ejecutivo': [],\n",
       " 'extras': [],\n",
       " 'estado_pedido': 'pendiente para confirmacion',\n",
       " 'platos_no_encontrados': []}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pregunta =      \"\"\"\n",
    "                Mister Alex\n",
    "                calle 12 #4 01 \n",
    "                salmon\n",
    "                \"\"\"\n",
    "\n",
    "inputs = {\n",
    "    \"pregunta\": pregunta ,\n",
    "    \"menu\": menu\n",
    "}\n",
    "\n",
    "\n",
    "pedido_json = cadena_pedidos.invoke(inputs)\n",
    "pedido_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena pedidos final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt_respuesta_pedido = PromptTemplate(\n",
    "    template=\"\"\" \n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "    Eres un asistente virtual del restaurante 'Juancho Plaza'. Tu tarea es responder a los clientes sobre el estado de sus pedidos, basándote en la estructura del pedido que has recibido en formato JSON. Debes verificar el estado del pedido y formular una respuesta adecuada.\n",
    "\n",
    "    Estructura del pedido:\n",
    "    {pedido_json}\n",
    "\n",
    "    Memoria de la conversación previa:\n",
    "    {memoria}\n",
    "\n",
    "    Debes seguir estas reglas para formular tu respuesta:\n",
    "    - Si el estado del pedido es `pendiente para confirmacion`, responde con un mensaje que confirme que el pedido ha sido recibido correctamente y está en espera de confirmación.\n",
    "    - Si el estado del pedido es `pedido_erroneo`, responde indicando que uno o más platos no están en el menú, y lista los productos que no se encontraron.\n",
    "    - Si el estado del pedido es `falta direccion`, informa al cliente que no se proporcionó una dirección y pídeles que la incluyan.\n",
    "    - Si el estado del pedido es `falta nombre`, informa al cliente que no se proporcionó un nombre y pídeles que lo incluyan.\n",
    "\n",
    "    Responde solo con el mensaje adecuado, sin agregar explicaciones adicionales.\n",
    "\n",
    "    Pregunta del cliente: {pregunta}\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"pedido_json\", \"pregunta\",\"memoria\"],\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "cadena_respuesta_pedido = prompt_respuesta_pedido | llm | StrOutputParser()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Estimado cliente, no se proporcionó un nombre para su pedido. Por favor, inclúyalo para poder procesar su solicitud.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"pregunta\": pregunta,\n",
    "    \"pedido_json\": pedido_json, \n",
    "    \"memoria\": memoria\n",
    "}\n",
    "\n",
    "\n",
    "pedido = cadena_respuesta_pedido.invoke(inputs)\n",
    "pedido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'falta nombre'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estado_pedido = pedido_json['estado_pedido']\n",
    "estado_pedido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcion_guardar_pedido_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "\n",
    "# Función para guardar el menú en la base de datos\n",
    "def guardar_menu_en_db(menu_juanchito_plaza, config):\n",
    "    connection = None  # Definir la variable fuera del bloque try\n",
    "    try:\n",
    "        # Configuración de conexión a MySQL\n",
    "        connection = mysql.connector.connect(**config)\n",
    "\n",
    "        if connection.is_connected():\n",
    "            cursor = connection.cursor()\n",
    "\n",
    "            # Inserción del menú en la tabla 'menus' (solo contenido_menu)\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO menus (contenido_menu) \n",
    "                VALUES (%s)\n",
    "            \"\"\", (menu_juanchito_plaza,))  # Se pasa el parámetro como una tupla\n",
    "\n",
    "            # Confirmar cambios\n",
    "            connection.commit()\n",
    "            print(\"Menú guardado exitosamente en la base de datos.\")\n",
    "\n",
    "    except Error as e:\n",
    "        print(f\"Error al guardar el menú en la base de datos: {e}\")\n",
    "    finally:\n",
    "        if connection is not None and connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"Conexión cerrada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcion_obtener_memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "def obtener_memoria(config, celular):\n",
    "    memoria = None  # Inicializar memoria\n",
    "\n",
    "    try:\n",
    "        # Conectar a la base de datos\n",
    "        connection = mysql.connector.connect(**config)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Verificar si el cliente ya está en la base de datos\n",
    "        query_check_celular = \"SELECT id FROM clientes WHERE telefono = %s\"\n",
    "        cursor.execute(query_check_celular, (celular,))\n",
    "        cliente = cursor.fetchone()\n",
    "\n",
    "        if cliente:\n",
    "            cliente_id = cliente[0]\n",
    "\n",
    "            # Recuperar la última conversación del cliente\n",
    "            query_get_last_conversacion = \"\"\"\n",
    "                SELECT mensaje_cliente_chatbot \n",
    "                FROM conversaciones_chatbot \n",
    "                WHERE cliente_id = %s \n",
    "                ORDER BY fecha_conversacion DESC \n",
    "                LIMIT 1\n",
    "            \"\"\"\n",
    "            cursor.execute(query_get_last_conversacion, (cliente_id,))\n",
    "            ultima_conversacion = cursor.fetchone()\n",
    "\n",
    "            if ultima_conversacion:\n",
    "                memoria = ultima_conversacion[0]\n",
    "                print(f\"Última conversación del cliente {cliente_id}: {memoria}\")\n",
    "            else:\n",
    "                memoria = \"No previous conversation found.\"\n",
    "                print(f\"No se encontró conversación previa para el cliente {cliente_id}.\")\n",
    "        else:\n",
    "            memoria = \"New customer, no conversation history.\"\n",
    "            print(f\"Cliente con el número {celular} no encontrado, es un nuevo cliente.\")\n",
    "            # Insertar al nuevo cliente en la tabla\n",
    "            query_insert_cliente = \"INSERT INTO clientes (telefono) VALUES (%s)\"\n",
    "            cursor.execute(query_insert_cliente, (celular,))\n",
    "            connection.commit()\n",
    "            cliente_id = cursor.lastrowid  # Obtener el nuevo ID del cliente\n",
    "            print(f\"Nuevo cliente agregado con ID: {cliente_id}\")\n",
    "\n",
    "    except Error as e:\n",
    "        print(f\"Error al interactuar con la base de datos: {e}\")\n",
    "    finally:\n",
    "        # Asegurarse de cerrar la conexión y el cursor\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if connection and connection.is_connected():\n",
    "            connection.close()\n",
    "            print(\"Conexión a MySQL cerrada.\")\n",
    "\n",
    "    return memoria\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcion_obtener_menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_ultimo_menu(config):\n",
    "\n",
    "    connection = mysql.connector.connect(**config)\n",
    "    \n",
    "    cursor = connection.cursor()\n",
    "    # Consulta SQL para obtener el contenido del menú más reciente\n",
    "    query = \"\"\"\n",
    "        SELECT contenido_menu \n",
    "        FROM menus \n",
    "        ORDER BY fecha_actualizacion DESC \n",
    "        LIMIT 1\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(query)\n",
    "    resultado = cursor.fetchone()  # Obtiene la primera fila del resultado\n",
    "    \n",
    "    if resultado:\n",
    "        return resultado[0]  # Retorna el contenido del menú\n",
    "    else:\n",
    "        return None  # Si no hay resultados, retorna None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nodo_pedido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pedido generado: {'nombre': 'Mister Alex', 'direccion': 'Morichal', 'a_la_carta': [{'producto': 'salmon', 'cantidad': 1}], 'menu_ejecutivo': [], 'extras': [], 'estado_pedido': 'pendiente_para_confirmacion', 'platos_no_encontrados': []}\n",
      "Última conversación del cliente 1: Cliente: \n",
      "            Mister Alex\n",
      "            Morichal\n",
      "            salmon\n",
      "             | Chatbot: Lamentablemente, su pedido ha sido marcado como \"pedido erróneo\" porque uno o más platos no están en el menú. En este caso, el producto que no se encontró es: salmon.\n",
      "Conexión a MySQL cerrada.\n",
      "Estado del pedido_json: Pendiente para confirmación\n",
      "(1, 'Mister Alex')\n",
      "Pedido guardado para el cliente con ID 1\n",
      "Conexión a MySQL cerrada.\n",
      "Conversación guardada exitosamente.\n",
      "Conexión a MySQL cerrada.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# def nodo_pedido(state):\n",
    "#print('---- nodo_pedido ----')\n",
    "\n",
    "# Obtener la pregunta y el celular del estado\n",
    "#pregunta = state[\"pregunta\"] \n",
    "#celular = state[\"celular\"]\n",
    "celular = 321\n",
    "pregunta = \"\"\"\n",
    "            Mister Alex\n",
    "            Morichal\n",
    "            salmon\n",
    "            \"\"\"\n",
    "            \n",
    "config = {\n",
    "    'user': 'root',\n",
    "    'password': '1234',\n",
    "    'host': 'localhost',\n",
    "    'port': 3306,\n",
    "    'database': 'juanchito_plaza'\n",
    "}\n",
    "\n",
    "# menu = obtener_ultimo_menu(config)\n",
    "\n",
    "inputs = {\n",
    "    \"pregunta\": pregunta,\n",
    "    \"menu\": menu\n",
    "}\n",
    "\n",
    "cadena_pedidos = prompt_pedidos | llm | JsonOutputParser()\n",
    "pedido_json = cadena_pedidos.invoke(inputs)\n",
    "print('Pedido generado:', pedido_json)\n",
    "\n",
    "# Extraer el estado del pedido\n",
    "estado_pedido = pedido_json.get('estado_pedido', None)\n",
    "\n",
    "memoria = obtener_memoria(config, celular)\n",
    "\n",
    "if estado_pedido == 'pendiente_para_confirmacion':\n",
    "    print('Estado del pedido_json: Pendiente para confirmación')\n",
    "\n",
    "    # Extraer el nombre y la dirección del JSON del pedido_json dentro del bloque\n",
    "    nombre_cliente = pedido_json.get('nombre', None)\n",
    "    direccion_cliente = pedido_json.get('direccion', None)\n",
    "\n",
    "    pedido_final = {\n",
    "        \"a_la_carta\": pedido_json.get('a_la_carta', []),\n",
    "        \"menu_ejecutivo\": pedido_json.get('menu_ejecutivo', []),\n",
    "        \"extras\": pedido_json.get('extras', [])\n",
    "    }\n",
    "\n",
    "    # Convierte el pedido_final a una cadena JSON\n",
    "    pedido_final_json = json.dumps(pedido_final)\n",
    "\n",
    "    try:\n",
    "        # Conectar a la base de datos\n",
    "        connection = mysql.connector.connect(**config)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Verificar si el cliente ya existe\n",
    "        query_check_celular = \"SELECT id, nombre FROM clientes WHERE telefono = %s\"\n",
    "        cursor.execute(query_check_celular, (celular,))\n",
    "        cliente = cursor.fetchone()\n",
    "\n",
    "        if cliente:\n",
    "            cliente_id, nombre_existente = cliente\n",
    "            print(cliente)\n",
    "        else:\n",
    "            print(\"Cliente no encontrado.\")\n",
    "            #return  # O puedes manejarlo de otra manera\n",
    "\n",
    "        if nombre_existente != nombre_cliente:\n",
    "            print(f\"Actualizando el nombre del cliente con número {celular}.\")\n",
    "            cursor.execute(\"UPDATE clientes SET nombre = %s WHERE id = %s\", (nombre_cliente, cliente_id))\n",
    "            connection.commit()\n",
    "\n",
    "        # Guardar el pedido en la tabla pedidos\n",
    "        query_insert_pedido = \"\"\"\n",
    "            INSERT INTO pedidos (cliente_id, pedido_json, direccion) \n",
    "            VALUES (%s, %s, %s)\n",
    "        \"\"\"\n",
    "        cursor.execute(query_insert_pedido, (cliente_id, pedido_final_json, direccion_cliente))\n",
    "        connection.commit()\n",
    "\n",
    "        print(f\"Pedido guardado para el cliente con ID {cliente_id}\")\n",
    "\n",
    "    except Error as e:\n",
    "        print(f\"Error al interactuar con la base de datos: {e}\")\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"Conexión a MySQL cerrada.\")\n",
    "\n",
    "elif estado_pedido in ['pedido_erroneo', 'falta_direccion', 'falta_nombre']:\n",
    "    print(f'Estado del pedido: {estado_pedido}')\n",
    "    \n",
    "    # Si el pedido es erróneo o falta información, puedes ejecutar la siguiente lógica\n",
    "    inputs = {\n",
    "        \"pregunta\": pregunta,\n",
    "        \"pedido_json\": pedido_json,  # Usar pedido_json en vez de pedido\n",
    "        \"memoria\": memoria\n",
    "    }\n",
    "\n",
    "    # Supongamos que cadena_respuesta_pedido maneja la respuesta del pedido erróneo\n",
    "    respuesta = cadena_respuesta_pedido.invoke(inputs)\n",
    "    print('Respuesta para el pedido erróneo o falta de información:', respuesta)\n",
    "    \n",
    "    \n",
    "try:\n",
    "    connection = mysql.connector.connect(**config)\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    # Verificar si el cliente existe\n",
    "    query_id_cliente = \"SELECT id FROM clientes WHERE telefono = %s\"\n",
    "    cursor.execute(query_id_cliente, (celular,))  # Wrap in a tuple\n",
    "    cliente = cursor.fetchone()\n",
    "\n",
    "    cliente_id = cliente[0]\n",
    "\n",
    "    # Insertar la conversación actual en la base de datos\n",
    "    query_insert_conversacion = \"\"\"\n",
    "        INSERT INTO conversaciones_chatbot (cliente_id, mensaje_cliente_chatbot) \n",
    "        VALUES (%s, %s)\n",
    "    \"\"\"\n",
    "    cursor.execute(query_insert_conversacion, (cliente_id, f\"Cliente: {pregunta} | Chatbot: {respuesta}\"))\n",
    "    connection.commit()\n",
    "    print(\"Conversación guardada exitosamente.\")\n",
    "\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"Error al interactuar con la base de datos: {e}\")\n",
    "\n",
    "finally:\n",
    "    if connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"Conexión a MySQL cerrada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Mister Alex')\n",
      "Error al interactuar con la base de datos: 1265 (01000): Data truncated for column 'estado_pedido' at row 1\n",
      "Conexión a MySQL cerrada.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Conectar a la base de datos\n",
    "    connection = mysql.connector.connect(**config)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Verificar si el cliente ya existe\n",
    "    query_check_celular = \"SELECT id, nombre FROM clientes WHERE telefono = %s\"\n",
    "    cursor.execute(query_check_celular, (celular,))\n",
    "    cliente = cursor.fetchone()\n",
    "\n",
    "    if cliente:\n",
    "        cliente_id, nombre_existente = cliente\n",
    "        print(cliente)\n",
    "    else:\n",
    "        print(\"Cliente no encontrado.\")\n",
    "        #return  # O puedes manejarlo de otra manera\n",
    "\n",
    "    if nombre_existente != nombre_cliente:\n",
    "        print(f\"Actualizando el nombre del cliente con número {celular}.\")\n",
    "        cursor.execute(\"UPDATE clientes SET nombre = %s WHERE id = %s\", (nombre_cliente, cliente_id))\n",
    "        connection.commit()\n",
    "\n",
    "    # Guardar el pedido en la tabla pedidos\n",
    "    query_insert_pedido = \"\"\"\n",
    "        INSERT INTO pedidos (cliente_id, pedido_json, direccion, estado_pedido) \n",
    "        VALUES (%s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    # Aquí asumimos que la confirmación inicial es False\n",
    "    confirmacion_pedido = False  # Por defecto, el pedido no está confirmado\n",
    "    cursor.execute(query_insert_pedido, (cliente_id, pedido_final_json, direccion_cliente, confirmacion_pedido))\n",
    "    connection.commit()\n",
    "\n",
    "    print(f\"Pedido guardado para el cliente con ID {cliente_id}\")\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"Error al interactuar con la base de datos: {e}\")\n",
    "finally:\n",
    "    if connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"Conexión a MySQL cerrada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def obtener_texto_imagen(image_path):\n",
    "  # Cargar la clave API desde las variables de entorno\n",
    "  api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "  # Getting the base64 string\n",
    "  base64_image = encode_image(image_path)\n",
    "\n",
    "  headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "  }\n",
    "\n",
    "  payload = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"dame los platos del menu ejecutivo de la imagen cada uno con su texto y precio, solo responde con el menu\"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "              \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"max_tokens\": 300\n",
    "  }\n",
    "\n",
    "  response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "  respuesta = response.json()\n",
    "\n",
    "  menu = respuesta['choices'][0]['message']['content']\n",
    "\n",
    "  return menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Menú Ejecutivo**\n",
      "\n",
      "1. **Sudado de Pollo** - $19.000  \n",
      "   * Pernil mixto en salsa criolla  \n",
      "   * Jugo del día  \n",
      "   * Ensalada de la casa  \n",
      "   * Arroz blanco  \n",
      "   * Sopa de avena  \n",
      "\n",
      "2. **Filet Mignon** - $18.000  \n",
      "   * Res en salsa de tocinetas y champiñones  \n",
      "   * Jugo natural del día  \n",
      "   * Ensalada de la huerta  \n",
      "   * Sopa de avena  \n",
      "\n",
      "3. **Bandeja Típica con Chicharrón** - $25.000  \n",
      "   * Porción de frijol + jugo + arroz blanco - ensalada y huevo frito  \n"
     ]
    }
   ],
   "source": [
    "image_path = \"C:/Users/sebas/chat-bot/juancho_plaza/chatbot/carta_juancho_plaza.jpg\"\n",
    "\n",
    "menu1 = obtener_texto_imagen(image_path)\n",
    "\n",
    "\n",
    "\n",
    "print(menu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    **Menú a la carta:**\n",
      "    1. **Churrasco + Chorizo** - $38.000\n",
      "    - 300 GRS. Sopas, Arroz, Jugo \n",
      "\n",
      "    2. **Salmón** - $38.000\n",
      "    - 180 GRS. Sopa o crema, ensalada, Arroz, Jugo \n",
      "\n",
      "    3. **Mojarra Frita** - $28.000\n",
      "    - 380 GRS. Sopa, Arroz, Jugo\n",
      "\n",
      "    4. **Punta de anca de cerdo** - $27.000\n",
      "    - Sopas, Arroz, Jugo, ensalada\n",
      "\n",
      "    5. **Filete de Trucha** - $20.000\n",
      "    - Sopas, Arroz, Jugo, ensalada\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Menú a la carta:**\n",
      "1. **Churrasco + Chorizo** - $38.000\n",
      "    - 300 GRS. Sopas, Arroz, Jugo \n",
      "\n",
      "2. **Salmón** - $38.000\n",
      "    - 180 GRS. Sopa o crema, ensalada, Arroz, Jugo \n",
      "\n",
      "3. **Mojarra Frita** - $28.000\n",
      "    - 380 GRS. Sopa, Arroz, Jugo\n",
      "\n",
      "4. **Punta de anca de cerdo** - $27.000\n",
      "    - Sopas, Arroz, Jugo, ensalada\n",
      "\n",
      "5. **Filete de Trucha** - $20.000\n",
      "    - Sopas, Arroz, Jugo, ensalada\n",
      "**Menú Ejecutivo**\n",
      "\n",
      "1. Sudado de Pollo - $19.000  \n",
      "   * Pernil mixto en salsa criolla  \n",
      "   * Jugo del día  \n",
      "   * Ensalada de la casa  \n",
      "   * Arroz blanco  \n",
      "   * Sopa de avena  \n",
      "\n",
      "2. Filet Mignon - $18.000  \n",
      "   * Res en salsa de tocinetas y champiñones  \n",
      "   * Jugo natural del día  \n",
      "   * Ensalada de la huerta  \n",
      "   * Sopa de avena  \n",
      "\n",
      "3. Bandeja Típica con Chicharrón - $25.000  \n",
      "   * Porción de frijol + Jugo + Arroz blanco - ensalada y huevo frito  \n"
     ]
    }
   ],
   "source": [
    "# Sumar (concatenar) los textos\n",
    "resultado = menu + menu1\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcion actualizar menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Función para guardar el menú en la base de datos\n",
    "def guardar_menu_en_db(menu_juanchito_plaza):\n",
    "    try:\n",
    "        # Configuración de conexión a MySQL\n",
    "        connection = mysql.connector.connect(**config)\n",
    "        \n",
    "        if connection.is_connected():\n",
    "            cursor = connection.cursor()\n",
    "\n",
    "            # Inserción del menú en la tabla 'menus' (solo contenido_menu)\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO menus (contenido_menu) \n",
    "                VALUES (%s)\n",
    "            \"\"\", (menu_juanchito_plaza,))  # Se pasa el parámetro como una tupla (notar la coma)\n",
    "\n",
    "            # Confirmar cambios\n",
    "            connection.commit()\n",
    "            print(\"Menú guardado exitosamente en la base de datos.\")\n",
    "\n",
    "    except Error as e:\n",
    "        print(f\"Error al guardar el menú en la base de datos: {e}\")\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "\n",
    "# Función para actualizar el menú\n",
    "def actualizar_menu(imagen, numero, menu_carta):\n",
    "    # Obtener el texto de la imagen\n",
    "    menu_ejecutivo = obtener_texto_imagen(imagen)\n",
    "\n",
    "    # Combinar los menús\n",
    "    menu_juanchito_plaza = menu_carta + \" \" + menu_ejecutivo\n",
    "\n",
    "    # Verificar si el número es 321\n",
    "    if numero == 321:\n",
    "        # Guardar el menú combinado en la base de datos\n",
    "        guardar_menu_en_db(menu_juanchito_plaza)\n",
    "\n",
    "        return \"Menu actualizado\"\n",
    "    else:\n",
    "        print(\"Número no válido. No se guardó el menú.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menú guardado exitosamente en la base de datos.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Menu actualizado'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "image_path = \"C:/Users/sebas/chat-bot/juancho_plaza/chatbot/carta_juancho_plaza.jpg\"  # Reemplazar con la ruta real\n",
    "numero = 321  # Número a verificar\n",
    "\n",
    "# Actualizar el menú\n",
    "respuesta =actualizar_menu(image_path, numero, menu)\n",
    "respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n**Menú a la carta:**\\n1. **Churrasco + Chorizo** - $38.000\\n    - 300 GRS. Sopas, Arroz, Jugo \\n\\n2. **Salmón** - $38.000\\n    - 180 GRS. Sopa o crema, ensalada, Arroz, Jugo \\n\\n3. **Mojarra Frita** - $28.000\\n    - 380 GRS. Sopa, Arroz, Jugo\\n\\n4. **Punta de anca de cerdo** - $27.000\\n    - Sopas, Arroz, Jugo, ensalada\\n\\n5. **Filete de Trucha** - $20.000\\n    - Sopas, Arroz, Jugo, ensalada\\n'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena_pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'correct', 'structured_order': {'name': 'sebastian gomez', 'address': 'calle 12 # 4-01', 'dishes': [{'dish': 'salmón', 'quantity': 2, 'extras': []}, {'dish': 'churrasco', 'quantity': 1, 'extras': []}]}, 'unavailable_dishes': [], 'error_message': ''}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    " \n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_pedidos2 = PromptTemplate(\n",
    "    template=\"\"\"  \n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "    The restaurant Juanchito Plazo needs to verify if the following message from a customer contains all the required information to place a delivery order. \n",
    "    The order must include the following:\n",
    "    1. The customer's name.\n",
    "    2. The delivery address.\n",
    "    3. The dishes they want to order (verified against the provided menu).\n",
    "\n",
    "    The current menu is: {menu}\n",
    "\n",
    "    Verify the following:\n",
    "    - The requested dishes are available in the menu provided. If any dish is not on the menu, mark it as incorrect and list the unavailable dishes.\n",
    "    - Accept dish names regardless of capitalization or accentuation. For example, \"Salmón\", \"salmon\", \"SALMÓN\", or \"salmón\" should all be considered valid and equal.\n",
    "\n",
    "    Convert any quantities written in words to numbers for the JSON response. \n",
    "\n",
    "    Respond in JSON format with the following keys:\n",
    "    - \"status\": \"correct\" or \"incorrect\" depending on whether all the required information is present and the dishes are valid.\n",
    "    - \"structured_order\": If the order is correct, return an object with the structure:\n",
    "      - \"name\": customer's name,\n",
    "      - \"address\": delivery address,\n",
    "      - \"dishes\": list of objects containing:\n",
    "        - \"dish\": name of the dish from the menu,\n",
    "        - \"quantity\": quantity requested (in numbers),\n",
    "        - \"extras\": optional list of extras or notes (e.g., \"sin cebolla\").\n",
    "    - \"unavailable_dishes\": If any dishes are not available in the menu, return a list with the names of those dishes.\n",
    "    - \"error_message\": If the order is incorrect, explain the reason.\n",
    "\n",
    "    Here is the customer's message:\n",
    "    {pregunta}\n",
    "    \"\"\",\n",
    "    input_variables=[\"menu\", \"pregunta\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "\n",
    "cadena_pedidos = prompt_pedidos2 | llm | JsonOutputParser()\n",
    "\n",
    "pregunta= \"\"\"sebastian gomez\n",
    "             calle 12 # 4-01\n",
    "             dos salmon, un churrasco\n",
    "            \"\"\"\n",
    "# Ejemplo de uso\n",
    "inputs = {\n",
    "    \"pregunta\": pregunta,\n",
    "    \"menu\": menu\n",
    "}\n",
    "\n",
    "respuesta_pedidos = cadena_pedidos.invoke(inputs)\n",
    "print(respuesta_pedidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: correct\n",
      "Name: sebastian gomez\n",
      "Address: calle 12 # 4-01\n",
      "Dish: salmón\n",
      "Quantity: 2\n",
      "Extras: []\n",
      "Dish: churrasco\n",
      "Quantity: 1\n",
      "Extras: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Acceder a los datos\n",
    "print(\"Status:\", respuesta_pedidos['status'])\n",
    "print(\"Name:\", respuesta_pedidos['structured_order']['name'])\n",
    "print(\"Address:\", respuesta_pedidos['structured_order']['address'])\n",
    "\n",
    "# Acceder a la lista de platos\n",
    "for dish in respuesta_pedidos['structured_order']['dishes']:\n",
    "    print(\"Dish:\", dish['dish'])\n",
    "    print(\"Quantity:\", dish['quantity'])\n",
    "    print(\"Extras:\", dish['extras'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"dish\": \"salmón\",\n",
      "        \"quantity\": 2,\n",
      "        \"extras\": []\n",
      "    },\n",
      "    {\n",
      "        \"dish\": \"churrasco\",\n",
      "        \"quantity\": 1,\n",
      "        \"extras\": []\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Acceder a la lista de platos\n",
    "platos = []\n",
    "for dish in respuesta_pedidos['structured_order']['dishes']:\n",
    "    plato_info = {\n",
    "        \"dish\": dish['dish'],\n",
    "        \"quantity\": dish['quantity'],\n",
    "        \"extras\": dish['extras']\n",
    "    }\n",
    "    platos.append(plato_info)\n",
    "\n",
    "# Convertir la lista de platos en JSON\n",
    "platos_json = json.dumps(platos, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Imprimir el JSON\n",
    "print(platos_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena pedido final2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola Sebastián Gómez,\\n\\nGracias por tu pedido. Sin embargo, lamento informarte que las pizzas no están disponibles en nuestro menú actual. Te invito a elegir entre los siguientes platos:\\n\\n1. **Churrasco + Chorizo** - $38.000\\n2. **Salmón** - $38.000\\n3. **Mojarra Frita** - $28.000\\n4. **Punta de anca de cerdo** - $27.000\\n5. **Filete de Trucha** - $20.000\\n\\nPor favor, házmelo saber qué plato te gustaría ordenar. ¡Espero tu respuesta!'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    " \n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Creando el template del prompt\n",
    "prompt_pedidos_final2 = PromptTemplate(\n",
    "    template=\"\"\" \n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are the order-taking assistant for Juancho Plaza, a restaurant. The customer has sent a message with details of their order. Your task is to review the message, check if all the necessary information is provided, and if the dishes requested are available on the menu. Based on this, generate an appropriate response in Spanish. \n",
    "\n",
    "    Here are the steps:\n",
    "    \n",
    "    1. If the customer's message includes all the necessary information, such as their **name**, and **dishes to order**, proceed to confirm the order.\n",
    "    2. If **any information is missing** (name or address), generate a polite response asking for the missing information. Mention which specific detail is missing.\n",
    "    3. If the customer orders dishes that are **not available on the menu** ({menu}), kindly inform them that the following dishes are not available and suggest they choose from the available menu items.\n",
    "    \n",
    "    Menu for today: {menu}\n",
    "\n",
    "    Customer message: {pregunta}\n",
    "\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"menu\", \"pregunta\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "\n",
    "cadena_pedidos = prompt_pedidos2 | llm | StrOutputParser()\n",
    "\n",
    "pregunta= \"\"\"sebastian gomez\n",
    "             calle 12 # 4-01\n",
    "             dos pizzas\n",
    "            \"\"\"\n",
    "# Ejemplo de uso\n",
    "inputs = {\n",
    "    \"pregunta\": pregunta,\n",
    "    \"menu\": menu\n",
    "}\n",
    "\n",
    "respuesta_pedidos = cadena_pedidos.invoke(inputs)\n",
    "respuesta_pedidos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funciones nodo pedidos 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_pedido_db(nombre_cliente, celular, direccion_cliente, pedido_final_json):\n",
    "    try:\n",
    "        # Conectar a la base de datos\n",
    "        connection = mysql.connector.connect(**config)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Verificar si el cliente ya existe\n",
    "        query_check_celular = \"SELECT id, nombre FROM clientes WHERE telefono = %s\"\n",
    "        cursor.execute(query_check_celular, (celular,))\n",
    "        cliente = cursor.fetchone()\n",
    "\n",
    "        if cliente:\n",
    "            cliente_id, nombre_existente = cliente\n",
    "            print(f\"Cliente encontrado: {cliente}\")\n",
    "            # Actualizar nombre del cliente si es diferente\n",
    "            if nombre_existente != nombre_cliente:\n",
    "                print(f\"Actualizando el nombre del cliente con número {celular}.\")\n",
    "                cursor.execute(\"UPDATE clientes SET nombre = %s WHERE id = %s\", (nombre_cliente, cliente_id))\n",
    "                connection.commit()\n",
    "        else:\n",
    "            # Si el cliente no existe, crear un nuevo cliente\n",
    "            print(\"Cliente no encontrado. Creando nuevo cliente.\")\n",
    "            query_insert_cliente = \"\"\"\n",
    "                INSERT INTO clientes (nombre, telefono) \n",
    "                VALUES (%s, %s)\n",
    "            \"\"\"\n",
    "            cursor.execute(query_insert_cliente, (nombre_cliente, celular))\n",
    "            connection.commit()\n",
    "            cliente_id = cursor.lastrowid  # Obtener el ID del nuevo cliente\n",
    "            print(f\"Nuevo cliente creado con ID {cliente_id}.\")\n",
    "\n",
    "        # Guardar el pedido en la tabla pedidos\n",
    "        query_insert_pedido = \"\"\"\n",
    "            INSERT INTO pedidos (cliente_id, pedido_json, direccion, pedido_cofirmado) \n",
    "            VALUES (%s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        # Aquí asumimos que la confirmación inicial es False\n",
    "        confirmacion_pedido = False  # Por defecto, el pedido no está confirmado\n",
    "        cursor.execute(query_insert_pedido, (cliente_id, pedido_final_json, direccion_cliente, confirmacion_pedido))\n",
    "        connection.commit()\n",
    "\n",
    "        print(f\"Pedido guardado para el cliente con ID {cliente_id}\")\n",
    "\n",
    "    except mysql.connector.Error as e:\n",
    "        print(f\"Error al interactuar con la base de datos: {e}\")\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"Conexión a MySQL cerrada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nodo pedido 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente encontrado: (3, 'sebastian gomez')\n",
      "Pedido guardado para el cliente con ID 3\n",
      "Conexión a MySQL cerrada.\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que 'menu' está definido anteriormente\n",
    "pregunta = \"\"\"sebastian gomez\n",
    "             calle 12 # 4-01\n",
    "             dos salmon\n",
    "            \"\"\"\n",
    "\n",
    "# Ejemplo de uso\n",
    "inputs = {\n",
    "    \"pregunta\": pregunta,\n",
    "    \"menu\": menu\n",
    "}\n",
    "\n",
    "# Procesar la pregunta utilizando el prompt y el modelo LLM\n",
    "cadena_pedidos2 = prompt_pedidos2 | llm | JsonOutputParser()\n",
    "respuesta_pedidos = cadena_pedidos2.invoke(inputs)\n",
    "\n",
    "celular = \"321\"\n",
    "estado_pedido = respuesta_pedidos['status']\n",
    "# Verificar si la respuesta contiene los datos necesarios\n",
    "if estado_pedido == \"correct\":\n",
    "    # Acceder a los datos\n",
    "    nombre_cliente = respuesta_pedidos['structured_order']['name']\n",
    "    direccion_cliente = respuesta_pedidos['structured_order']['address']\n",
    "\n",
    "    # Acceder a la lista de platos\n",
    "    platos = []\n",
    "    for dish in respuesta_pedidos['structured_order']['dishes']:\n",
    "        plato_info = {\n",
    "            \"dish\": dish['dish'],\n",
    "            \"quantity\": dish['quantity'],\n",
    "            \"extras\": dish['extras']\n",
    "        }\n",
    "        platos.append(plato_info)\n",
    "\n",
    "    # Convertir la lista de platos en JSON\n",
    "    platos_json = json.dumps(platos, ensure_ascii=False, indent=4)\n",
    "\n",
    "    \n",
    "    # Guardar el pedido en la base de datos\n",
    "    guardar_pedido_db(nombre_cliente, celular, direccion_cliente, platos_json)\n",
    "else:\n",
    "    print(\"El pedido no es válido:\", respuesta_pedidos['error_message'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n    \"status\": \"correct\",\\n    \"structured_order\": {\\n        \"name\": \"sebastian gomez\",\\n        \"address\": \"calle 12 # 4-01\",\\n        \"dishes\": [\\n            {\\n                \"dish\": \"Salmón\",\\n                \"quantity\": 2,\\n                \"extras\": []\\n            }\\n        ]\\n    },\\n    \"unavailable_dishes\": [],\\n    \"error_message\": \"\"\\n}\\n```'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuesta_pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[192], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convertir la cadena JSON a un diccionario\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m respuesta_pedidos \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrespuesta_pedidos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Acceder a los datos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m status \u001b[38;5;241m=\u001b[39m respuesta_pedidos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sebas\\python\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\sebas\\python\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\sebas\\python\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Convertir la cadena JSON a un diccionario\n",
    "respuesta_pedidos = json.loads(respuesta_pedidos)\n",
    "\n",
    "# Acceder a los datos\n",
    "status = respuesta_pedidos['status']\n",
    "nombre_cliente = respuesta_pedidos['structured_order']['name']\n",
    "direccion_cliente = respuesta_pedidos['structured_order']['address']\n",
    "dishes = respuesta_pedidos['structured_order']['dishes']\n",
    "\n",
    "# Imprimir los datos\n",
    "if status == \"correct\":\n",
    "    print(\"Estado del pedido:\", status)\n",
    "    print(\"Nombre del Cliente:\", nombre_cliente)\n",
    "    print(\"Dirección del Cliente:\", direccion_cliente)\n",
    "    print(\"Pedido:\")\n",
    "    for dish in dishes:\n",
    "        print(f\" - Plato: {dish['dish']}, Cantidad: {dish['quantity']}, Extras: {dish['extras']}\")\n",
    "else:\n",
    "    print(\"El pedido es incorrecto.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena final 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La capital de Colombia es Bogotá. 😊 Soy el chatbot de Juancho Plaza y puedo ayudarte con tu pedido. Ofrecemos entregas solo en la *Zona Industrial Maltería*, desde *Bosque Popular* hasta *Oncólogos*. Tomamos pedidos hasta las *11 a.m*. Por favor, proporciona tu nombre, dirección y los platos del menú que te gustaría pedir.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Creando el template del prompt\n",
    "prompt_final2 = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    message: {message} \n",
    "\n",
    "    You are Juancho Plaza's order-taking chatbot. If the message contains a greeting (such as \"hola\", \"buenos dias\", \"buenas tardes\"), respond with the following:\n",
    "    \n",
    "    😊 Hello! I am Juancho Plaza's chatbot, and I can help you with your order. We offer deliveries only in the *Maltería Industrial Zone*, from *Bosque Popular* to *Oncólogos*. We take orders until *11 a.m*. Please provide your name, address, and the dishes from the menu that you would like to order.\n",
    "\n",
    "    If the message contains a question about delivery times, respond by saying: \"We take orders until *11 a.m*.\"\n",
    "\n",
    "    If the message contains a question about delivery areas, respond by saying: \"We offer deliveries only in the *Maltería Industrial Zone*, from *Bosque Popular* to *Oncólogos*.\"\n",
    "\n",
    "    If the message does not contain a greeting, first respond to the customer's message and then provide the following order-taking information:\n",
    "\n",
    "    Personalized response to the customer's message, 😊 I am Juancho Plaza's chatbot, I can help you with your order.\n",
    "\n",
    "    Generate the resonse pin Spanish.\n",
    "    Response:\n",
    "    \"\"\",\n",
    "    input_variables=[\"message\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Configurando el modelo LLM\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "\n",
    "# Configurando la cadena de decisión\n",
    "cadena_final2 = prompt_final2 | llm | StrOutputParser()\n",
    "\n",
    "# Mensaje de prueba\n",
    "pregunta = \"\"\"\n",
    "            cual es la capital de colombia\n",
    "            \"\"\"\n",
    "\n",
    "# Ejecutando el modelo\n",
    "response = cadena_final2.invoke({\"message\": pregunta})\n",
    "\n",
    "# Imprimiendo el resultado\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
