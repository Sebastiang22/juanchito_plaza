{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langfuse in c:\\users\\sebas\\python\\lib\\site-packages (2.50.3)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.4.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (4.6.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (0.26.0)\n",
      "Requirement already satisfied: idna<4.0,>=3.7 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (3.10)\n",
      "Requirement already satisfied: packaging<25.0,>=23.2 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (2.5.2)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (1.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sebas\\python\\lib\\site-packages (from anyio<5.0.0,>=4.4.0->langfuse) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sebas\\python\\lib\\site-packages (from httpx<1.0,>=0.15.4->langfuse) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sebas\\python\\lib\\site-packages (from httpx<1.0,>=0.15.4->langfuse) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sebas\\python\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sebas\\python\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\sebas\\python\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\sebas\\python\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\sebas\\python\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: langgraph in c:\\users\\sebas\\python\\lib\\site-packages (0.2.19)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\sebas\\python\\lib\\site-packages (0.1.22)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\sebas\\python\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (3.9.4)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (0.2.39)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (0.2.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (0.1.117)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in c:\\users\\sebas\\python\\lib\\site-packages (from langgraph) (1.0.9)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain_openai) (1.42.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain_community) (0.6.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sebas\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sebas\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sebas\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sebas\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sebas\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sebas\\python\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\sebas\\python\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.26.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sebas\\python\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sebas\\python\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sebas\\python\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sebas\\python\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sebas\\python\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sebas\\python\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sebas\\python\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\sebas\\python\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.14.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sebas\\python\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sebas\\python\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sebas\\python\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sebas\\python\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sebas\\python\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\sebas\\python\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sebas\\python\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sebas\\python\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sebas\\python\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (2.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sebas\\python\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.40.0->langchain_openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sebas\\python\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install langfuse\n",
    "%pip install langchain langgraph langchain_openai langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-lf-d572a246-a761-447e-9adf-2cffce9b3083\n",
      "pk-lf-41aceb5f-9530-4eaf-aefb-63f279dc084f\n",
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    " # Carga las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "# get keys for your project from https://cloud.langfuse.com\n",
    "\n",
    "print(os.getenv(\"LANGFUSE_SECRET_KEY\"))\n",
    "print(os.getenv(\"LANGFUSE_PUBLIC_KEY\"))\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # for EU data region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # for US data region\n",
    " \n",
    "# your openai key\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))        # \"your-openai-api-key\"\n",
    "\n",
    "\n",
    "config = {\n",
    "    'user': 'root',\n",
    "    'password': 'password',\n",
    "    'host': 'localhost',\n",
    "    'port': 3308,\n",
    "    'database': 'juanchito_plaza'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objeto datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "\n",
    "class objeto_juancho_plaza(TypedDict):\n",
    "    # Primer nodo: decisión sobre la función a realizar\n",
    "    celular: str  # Número de teléfono del usuario\n",
    "    pregunta: str  # Pregunta original del usuario\n",
    "    decision: str  # Decisión sobre qué función ejecutar ('crear_usuario', 'consulta_sql', 'crear_pago')\n",
    "\n",
    "    # Nodos intermedios: detalles específicos para cada función\n",
    "    pedido: dict  # Contendrá detalles de un nuevo usuario (nombre, email, etc.)\n",
    "    \n",
    "    # Nodo final: respuesta generada\n",
    "    respuesta: str  # Respuesta final del chatbot después de procesar la solicitud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'funcion': 'carta'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt_decision = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "    Eres un experto en gestionar operaciones de un sistema de pedidos de comida. Tienes tres funciones principales:\n",
    "    1. 'pedido': Usar esta función si la pregunta está relacionada platos del menú, el nombre del cliente o la direccion.\n",
    "    2. 'confirmacion': Usar esta función si la pregunta está relacionada con confirmar un pedido o si la pregunta solo es si.\n",
    "    3. 'carta': Usar esta función si la pregunta está relacionada con consultar los platos o la carta del restaurante.\n",
    "\n",
    "    No necesitas ser estricto con las palabras clave, identifica el propósito general de la pregunta para seleccionar la opción adecuada. \n",
    "    Da una opción binaria ('pedido', 'confirmacion','carta) basada en la pregunta. \n",
    "    Retorna un JSON con solo una clave 'funcion' sin preámbulo o explicación.\n",
    "\n",
    "    Pregunta a enrutar: {pregunta}\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"pregunta\"],\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "\n",
    "cadena_decision = prompt_decision | llm | JsonOutputParser()\n",
    "\n",
    "pregunta = \"carta\"\n",
    "print(cadena_decision.invoke({\"pregunta\": pregunta}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = \"\"\"\n",
    "**Menú a la carta:**\n",
    "1. **Churrasco + Chorizo** - $38.000\n",
    "    - 300 GRS. Sopas, Arroz, Jugo \n",
    "\n",
    "2. **Salmón** - $38.000\n",
    "    - 180 GRS. Sopa o crema, ensalada, Arroz, Jugo \n",
    "\n",
    "3. **Mojarra Frita** - $28.000\n",
    "    - 380 GRS. Sopa, Arroz, Jugo\n",
    "\n",
    "4. **Punta de anca de cerdo** - $27.000\n",
    "    - Sopas, Arroz, Jugo, ensalada\n",
    "\n",
    "5. **Filete de Trucha** - $20.000\n",
    "    - Sopas, Arroz, Jugo, ensalada\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def obtener_texto_imagen(image_path):\n",
    "  # Cargar la clave API desde las variables de entorno\n",
    "  api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "  # Getting the base64 string\n",
    "  base64_image = encode_image(image_path)\n",
    "\n",
    "  headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "  }\n",
    "\n",
    "  payload = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"dame los platos del menu ejecutivo de la imagen cada uno con su texto y precio, solo responde con el menu\"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "              \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"max_tokens\": 300\n",
    "  }\n",
    "\n",
    "  response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "  respuesta = response.json()\n",
    "\n",
    "  menu = respuesta['choices'][0]['message']['content']\n",
    "\n",
    "  return menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Menú Ejecutivo**\n",
      "\n",
      "1. **Sudado de Pollo** - $19.000  \n",
      "   * Pernil mixto en salsa criolla  \n",
      "   * Jugo del día  \n",
      "   * Ensalada de la casa  \n",
      "   * Arroz blanco  \n",
      "   * Sopa de avena  \n",
      "\n",
      "2. **Filet Mignon** - $18.000  \n",
      "   * Res en salsa de tocinetas y champiñones  \n",
      "   * Jugo natural del día  \n",
      "   * Ensalada de la huerta  \n",
      "   * Sopa de avena  \n",
      "\n",
      "3. **Bandeja Típica con Chicharrón** - $25.000  \n",
      "   * Porción de frijol + jugo + arroz blanco - ensalada y huevo frito  \n"
     ]
    }
   ],
   "source": [
    "image_path = \"C:/Users/sebas/chat-bot/juancho_plaza/chatbot/carta_juancho_plaza.jpg\"\n",
    "\n",
    "menu1 = obtener_texto_imagen(image_path)\n",
    "\n",
    "\n",
    "\n",
    "print(menu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    **Menú a la carta:**\n",
      "    1. **Churrasco + Chorizo** - $38.000\n",
      "    - 300 GRS. Sopas, Arroz, Jugo \n",
      "\n",
      "    2. **Salmón** - $38.000\n",
      "    - 180 GRS. Sopa o crema, ensalada, Arroz, Jugo \n",
      "\n",
      "    3. **Mojarra Frita** - $28.000\n",
      "    - 380 GRS. Sopa, Arroz, Jugo\n",
      "\n",
      "    4. **Punta de anca de cerdo** - $27.000\n",
      "    - Sopas, Arroz, Jugo, ensalada\n",
      "\n",
      "    5. **Filete de Trucha** - $20.000\n",
      "    - Sopas, Arroz, Jugo, ensalada\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Menú a la carta:**\n",
      "1. **Churrasco + Chorizo** - $38.000\n",
      "    - 300 GRS. Sopas, Arroz, Jugo \n",
      "\n",
      "2. **Salmón** - $38.000\n",
      "    - 180 GRS. Sopa o crema, ensalada, Arroz, Jugo \n",
      "\n",
      "3. **Mojarra Frita** - $28.000\n",
      "    - 380 GRS. Sopa, Arroz, Jugo\n",
      "\n",
      "4. **Punta de anca de cerdo** - $27.000\n",
      "    - Sopas, Arroz, Jugo, ensalada\n",
      "\n",
      "5. **Filete de Trucha** - $20.000\n",
      "    - Sopas, Arroz, Jugo, ensalada\n",
      "**Menú Ejecutivo**\n",
      "\n",
      "1. Sudado de Pollo - $19.000  \n",
      "   * Pernil mixto en salsa criolla  \n",
      "   * Jugo del día  \n",
      "   * Ensalada de la casa  \n",
      "   * Arroz blanco  \n",
      "   * Sopa de avena  \n",
      "\n",
      "2. Filet Mignon - $18.000  \n",
      "   * Res en salsa de tocinetas y champiñones  \n",
      "   * Jugo natural del día  \n",
      "   * Ensalada de la huerta  \n",
      "   * Sopa de avena  \n",
      "\n",
      "3. Bandeja Típica con Chicharrón - $25.000  \n",
      "   * Porción de frijol + Jugo + Arroz blanco - ensalada y huevo frito  \n"
     ]
    }
   ],
   "source": [
    "# Sumar (concatenar) los textos\n",
    "resultado = menu + menu1\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcion actualizar menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Función para guardar el menú en la base de datos\n",
    "def guardar_menu_en_db(menu_juanchito_plaza):\n",
    "    try:\n",
    "        # Configuración de conexión a MySQL\n",
    "        connection = mysql.connector.connect(**config)\n",
    "        \n",
    "        if connection.is_connected():\n",
    "            cursor = connection.cursor()\n",
    "\n",
    "            # Inserción del menú en la tabla 'menus' (solo contenido_menu)\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO menus (contenido_menu) \n",
    "                VALUES (%s)\n",
    "            \"\"\", (menu_juanchito_plaza,))  # Se pasa el parámetro como una tupla (notar la coma)\n",
    "\n",
    "            # Confirmar cambios\n",
    "            connection.commit()\n",
    "            print(\"Menú guardado exitosamente en la base de datos.\")\n",
    "\n",
    "    except Error as e:\n",
    "        print(f\"Error al guardar el menú en la base de datos: {e}\")\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "\n",
    "# Función para actualizar el menú\n",
    "def actualizar_menu(imagen, numero, menu_carta):\n",
    "    # Obtener el texto de la imagen\n",
    "    menu_ejecutivo = obtener_texto_imagen(imagen)\n",
    "\n",
    "    # Combinar los menús\n",
    "    menu_juanchito_plaza = menu_carta + \" \" + menu_ejecutivo\n",
    "\n",
    "    # Verificar si el número es 321\n",
    "    if numero == 321:\n",
    "        # Guardar el menú combinado en la base de datos\n",
    "        guardar_menu_en_db(menu_juanchito_plaza)\n",
    "\n",
    "        return \"Menu actualizado\"\n",
    "    else:\n",
    "        print(\"Número no válido. No se guardó el menú.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menú guardado exitosamente en la base de datos.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Menu actualizado'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "image_path = \"C:/Users/sebas/chat-bot/juancho_plaza/chatbot/carta_juancho_plaza.jpg\"  # Reemplazar con la ruta real\n",
    "numero = 321  # Número a verificar\n",
    "\n",
    "# Actualizar el menú\n",
    "respuesta =actualizar_menu(image_path, numero, menu)\n",
    "respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n**Menú a la carta:**\\n1. **Churrasco + Chorizo** - $38.000\\n    - 300 GRS. Sopas, Arroz, Jugo \\n\\n2. **Salmón** - $38.000\\n    - 180 GRS. Sopa o crema, ensalada, Arroz, Jugo \\n\\n3. **Mojarra Frita** - $28.000\\n    - 380 GRS. Sopa, Arroz, Jugo\\n\\n4. **Punta de anca de cerdo** - $27.000\\n    - Sopas, Arroz, Jugo, ensalada\\n\\n5. **Filete de Trucha** - $20.000\\n    - Sopas, Arroz, Jugo, ensalada\\n'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena_pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'correct', 'structured_order': {'name': 'sebastian gomez', 'address': 'calle 12 # 4-01', 'dishes': [{'dish': 'salmón', 'quantity': 2, 'extras': []}, {'dish': 'churrasco', 'quantity': 1, 'extras': []}]}, 'unavailable_dishes': [], 'error_message': ''}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    " \n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_pedidos2 = PromptTemplate(\n",
    "    template=\"\"\"  \n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "    The restaurant Juanchito Plazo needs to verify if the following message from a customer contains all the required information to place a delivery order. \n",
    "    The order must include the following:\n",
    "    1. The customer's name.\n",
    "    2. The delivery address.\n",
    "    3. The dishes they want to order (verified against the provided menu).\n",
    "\n",
    "    The current menu is: {menu}\n",
    "\n",
    "    Verify the following:\n",
    "    - The requested dishes are available in the menu provided. If any dish is not on the menu, mark it as incorrect and list the unavailable dishes.\n",
    "    - Accept dish names regardless of capitalization or accentuation. For example, \"Salmón\", \"salmon\", \"SALMÓN\", or \"salmón\" should all be considered valid and equal.\n",
    "\n",
    "    Convert any quantities written in words to numbers for the JSON response. \n",
    "\n",
    "    Respond in JSON format with the following keys:\n",
    "    - \"status\": \"correct\" or \"incorrect\" depending on whether all the required information is present and the dishes are valid.\n",
    "    - \"structured_order\": If the order is correct, return an object with the structure:\n",
    "      - \"name\": customer's name,\n",
    "      - \"address\": delivery address,\n",
    "      - \"dishes\": list of objects containing:\n",
    "        - \"dish\": name of the dish from the menu,\n",
    "        - \"quantity\": quantity requested (in numbers),\n",
    "        - \"extras\": optional list of extras or notes (e.g., \"sin cebolla\").\n",
    "    - \"unavailable_dishes\": If any dishes are not available in the menu, return a list with the names of those dishes.\n",
    "    - \"error_message\": If the order is incorrect, explain the reason.\n",
    "\n",
    "    Here is the customer's message:\n",
    "    {pregunta}\n",
    "    \"\"\",\n",
    "    input_variables=[\"menu\", \"pregunta\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "\n",
    "cadena_pedidos = prompt_pedidos2 | llm | JsonOutputParser()\n",
    "\n",
    "pregunta= \"\"\"sebastian gomez\n",
    "             calle 12 # 4-01\n",
    "             dos salmon, un churrasco\n",
    "            \"\"\"\n",
    "# Ejemplo de uso\n",
    "inputs = {\n",
    "    \"pregunta\": pregunta,\n",
    "    \"menu\": menu\n",
    "}\n",
    "\n",
    "respuesta_pedidos = cadena_pedidos.invoke(inputs)\n",
    "print(respuesta_pedidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: correct\n",
      "Name: sebastian gomez\n",
      "Address: calle 12 # 4-01\n",
      "Dish: salmón\n",
      "Quantity: 2\n",
      "Extras: []\n",
      "Dish: churrasco\n",
      "Quantity: 1\n",
      "Extras: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Acceder a los datos\n",
    "print(\"Status:\", respuesta_pedidos['status'])\n",
    "print(\"Name:\", respuesta_pedidos['structured_order']['name'])\n",
    "print(\"Address:\", respuesta_pedidos['structured_order']['address'])\n",
    "\n",
    "# Acceder a la lista de platos\n",
    "for dish in respuesta_pedidos['structured_order']['dishes']:\n",
    "    print(\"Dish:\", dish['dish'])\n",
    "    print(\"Quantity:\", dish['quantity'])\n",
    "    print(\"Extras:\", dish['extras'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"dish\": \"salmón\",\n",
      "        \"quantity\": 2,\n",
      "        \"extras\": []\n",
      "    },\n",
      "    {\n",
      "        \"dish\": \"churrasco\",\n",
      "        \"quantity\": 1,\n",
      "        \"extras\": []\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Acceder a la lista de platos\n",
    "platos = []\n",
    "for dish in respuesta_pedidos['structured_order']['dishes']:\n",
    "    plato_info = {\n",
    "        \"dish\": dish['dish'],\n",
    "        \"quantity\": dish['quantity'],\n",
    "        \"extras\": dish['extras']\n",
    "    }\n",
    "    platos.append(plato_info)\n",
    "\n",
    "# Convertir la lista de platos en JSON\n",
    "platos_json = json.dumps(platos, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Imprimir el JSON\n",
    "print(platos_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena pedido final2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola Sebastián Gómez,\\n\\nGracias por tu pedido. Sin embargo, lamento informarte que las pizzas no están disponibles en nuestro menú actual. Te invito a elegir entre los siguientes platos:\\n\\n1. **Churrasco + Chorizo** - $38.000\\n2. **Salmón** - $38.000\\n3. **Mojarra Frita** - $28.000\\n4. **Punta de anca de cerdo** - $27.000\\n5. **Filete de Trucha** - $20.000\\n\\nPor favor, házmelo saber qué plato te gustaría ordenar. ¡Espero tu respuesta!'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    " \n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Creando el template del prompt\n",
    "prompt_pedidos_final2 = PromptTemplate(\n",
    "    template=\"\"\" \n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are the order-taking assistant for Juancho Plaza, a restaurant. The customer has sent a message with details of their order. Your task is to review the message, check if all the necessary information is provided, and if the dishes requested are available on the menu. Based on this, generate an appropriate response in Spanish. \n",
    "\n",
    "    Here are the steps:\n",
    "    \n",
    "    1. If the customer's message includes all the necessary information, such as their **name**, and **dishes to order**, proceed to confirm the order.\n",
    "    2. If **any information is missing** (name or address), generate a polite response asking for the missing information. Mention which specific detail is missing.\n",
    "    3. If the customer orders dishes that are **not available on the menu** ({menu}), kindly inform them that the following dishes are not available and suggest they choose from the available menu items.\n",
    "    \n",
    "    Menu for today: {menu}\n",
    "\n",
    "    Customer message: {pregunta}\n",
    "\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"menu\", \"pregunta\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "\n",
    "cadena_pedidos = prompt_pedidos2 | llm | StrOutputParser()\n",
    "\n",
    "pregunta= \"\"\"sebastian gomez\n",
    "             calle 12 # 4-01\n",
    "             dos pizzas\n",
    "            \"\"\"\n",
    "# Ejemplo de uso\n",
    "inputs = {\n",
    "    \"pregunta\": pregunta,\n",
    "    \"menu\": menu\n",
    "}\n",
    "\n",
    "respuesta_pedidos = cadena_pedidos.invoke(inputs)\n",
    "respuesta_pedidos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funciones nodo pedidos 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_pedido_db(nombre_cliente, celular, direccion_cliente, pedido_final_json):\n",
    "    try:\n",
    "        # Conectar a la base de datos\n",
    "        connection = mysql.connector.connect(**config)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Verificar si el cliente ya existe\n",
    "        query_check_celular = \"SELECT id, nombre FROM clientes WHERE telefono = %s\"\n",
    "        cursor.execute(query_check_celular, (celular,))\n",
    "        cliente = cursor.fetchone()\n",
    "\n",
    "        if cliente:\n",
    "            cliente_id, nombre_existente = cliente\n",
    "            print(f\"Cliente encontrado: {cliente}\")\n",
    "            # Actualizar nombre del cliente si es diferente\n",
    "            if nombre_existente != nombre_cliente:\n",
    "                print(f\"Actualizando el nombre del cliente con número {celular}.\")\n",
    "                cursor.execute(\"UPDATE clientes SET nombre = %s WHERE id = %s\", (nombre_cliente, cliente_id))\n",
    "                connection.commit()\n",
    "        else:\n",
    "            # Si el cliente no existe, crear un nuevo cliente\n",
    "            print(\"Cliente no encontrado. Creando nuevo cliente.\")\n",
    "            query_insert_cliente = \"\"\"\n",
    "                INSERT INTO clientes (nombre, telefono) \n",
    "                VALUES (%s, %s)\n",
    "            \"\"\"\n",
    "            cursor.execute(query_insert_cliente, (nombre_cliente, celular))\n",
    "            connection.commit()\n",
    "            cliente_id = cursor.lastrowid  # Obtener el ID del nuevo cliente\n",
    "            print(f\"Nuevo cliente creado con ID {cliente_id}.\")\n",
    "\n",
    "        # Guardar el pedido en la tabla pedidos\n",
    "        query_insert_pedido = \"\"\"\n",
    "            INSERT INTO pedidos (cliente_id, pedido_json, direccion, pedido_cofirmado) \n",
    "            VALUES (%s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        # Aquí asumimos que la confirmación inicial es False\n",
    "        confirmacion_pedido = False  # Por defecto, el pedido no está confirmado\n",
    "        cursor.execute(query_insert_pedido, (cliente_id, pedido_final_json, direccion_cliente, confirmacion_pedido))\n",
    "        connection.commit()\n",
    "\n",
    "        print(f\"Pedido guardado para el cliente con ID {cliente_id}\")\n",
    "\n",
    "    except mysql.connector.Error as e:\n",
    "        print(f\"Error al interactuar con la base de datos: {e}\")\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"Conexión a MySQL cerrada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nodo pedido 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente encontrado: (3, 'sebastian gomez')\n",
      "Pedido guardado para el cliente con ID 3\n",
      "Conexión a MySQL cerrada.\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que 'menu' está definido anteriormente\n",
    "pregunta = \"\"\"sebastian gomez\n",
    "             calle 12 # 4-01\n",
    "             dos salmon\n",
    "            \"\"\"\n",
    "\n",
    "# Ejemplo de uso\n",
    "inputs = {\n",
    "    \"pregunta\": pregunta,\n",
    "    \"menu\": menu\n",
    "}\n",
    "\n",
    "# Procesar la pregunta utilizando el prompt y el modelo LLM\n",
    "cadena_pedidos2 = prompt_pedidos2 | llm | JsonOutputParser()\n",
    "respuesta_pedidos = cadena_pedidos2.invoke(inputs)\n",
    "\n",
    "celular = \"321\"\n",
    "estado_pedido = respuesta_pedidos['status']\n",
    "# Verificar si la respuesta contiene los datos necesarios\n",
    "if estado_pedido == \"correct\":\n",
    "    # Acceder a los datos\n",
    "    nombre_cliente = respuesta_pedidos['structured_order']['name']\n",
    "    direccion_cliente = respuesta_pedidos['structured_order']['address']\n",
    "\n",
    "    # Acceder a la lista de platos\n",
    "    platos = []\n",
    "    for dish in respuesta_pedidos['structured_order']['dishes']:\n",
    "        plato_info = {\n",
    "            \"dish\": dish['dish'],\n",
    "            \"quantity\": dish['quantity'],\n",
    "            \"extras\": dish['extras']\n",
    "        }\n",
    "        platos.append(plato_info)\n",
    "\n",
    "    # Convertir la lista de platos en JSON\n",
    "    platos_json = json.dumps(platos, ensure_ascii=False, indent=4)\n",
    "\n",
    "    \n",
    "    # Guardar el pedido en la base de datos\n",
    "    guardar_pedido_db(nombre_cliente, celular, direccion_cliente, platos_json)\n",
    "else:\n",
    "    print(\"El pedido no es válido:\", respuesta_pedidos['error_message'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n    \"status\": \"correct\",\\n    \"structured_order\": {\\n        \"name\": \"sebastian gomez\",\\n        \"address\": \"calle 12 # 4-01\",\\n        \"dishes\": [\\n            {\\n                \"dish\": \"Salmón\",\\n                \"quantity\": 2,\\n                \"extras\": []\\n            }\\n        ]\\n    },\\n    \"unavailable_dishes\": [],\\n    \"error_message\": \"\"\\n}\\n```'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuesta_pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[192], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convertir la cadena JSON a un diccionario\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m respuesta_pedidos \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrespuesta_pedidos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Acceder a los datos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m status \u001b[38;5;241m=\u001b[39m respuesta_pedidos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sebas\\python\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\sebas\\python\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\sebas\\python\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Convertir la cadena JSON a un diccionario\n",
    "respuesta_pedidos = json.loads(respuesta_pedidos)\n",
    "\n",
    "# Acceder a los datos\n",
    "status = respuesta_pedidos['status']\n",
    "nombre_cliente = respuesta_pedidos['structured_order']['name']\n",
    "direccion_cliente = respuesta_pedidos['structured_order']['address']\n",
    "dishes = respuesta_pedidos['structured_order']['dishes']\n",
    "\n",
    "# Imprimir los datos\n",
    "if status == \"correct\":\n",
    "    print(\"Estado del pedido:\", status)\n",
    "    print(\"Nombre del Cliente:\", nombre_cliente)\n",
    "    print(\"Dirección del Cliente:\", direccion_cliente)\n",
    "    print(\"Pedido:\")\n",
    "    for dish in dishes:\n",
    "        print(f\" - Plato: {dish['dish']}, Cantidad: {dish['quantity']}, Extras: {dish['extras']}\")\n",
    "else:\n",
    "    print(\"El pedido es incorrecto.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena final 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La capital de Colombia es Bogotá. 😊 Soy el chatbot de Juancho Plaza y puedo ayudarte con tu pedido. Ofrecemos entregas solo en la *Zona Industrial Maltería*, desde *Bosque Popular* hasta *Oncólogos*. Tomamos pedidos hasta las *11 a.m*. Por favor, proporciona tu nombre, dirección y los platos del menú que te gustaría pedir.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Creando el template del prompt\n",
    "prompt_final2 = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    message: {message} \n",
    "\n",
    "    You are Juancho Plaza's order-taking chatbot. If the message contains a greeting (such as \"hola\", \"buenos dias\", \"buenas tardes\"), respond with the following:\n",
    "    \n",
    "    😊 Hello! I am Juancho Plaza's chatbot, and I can help you with your order. We offer deliveries only in the *Maltería Industrial Zone*, from *Bosque Popular* to *Oncólogos*. We take orders until *11 a.m*. Please provide your name, address, and the dishes from the menu that you would like to order.\n",
    "\n",
    "    If the message contains a question about delivery times, respond by saying: \"We take orders until *11 a.m*.\"\n",
    "\n",
    "    If the message contains a question about delivery areas, respond by saying: \"We offer deliveries only in the *Maltería Industrial Zone*, from *Bosque Popular* to *Oncólogos*.\"\n",
    "\n",
    "    If the message does not contain a greeting, first respond to the customer's message and then provide the following order-taking information:\n",
    "\n",
    "    Personalized response to the customer's message, 😊 I am Juancho Plaza's chatbot, I can help you with your order.\n",
    "\n",
    "    Generate the resonse pin Spanish.\n",
    "    Response:\n",
    "    \"\"\",\n",
    "    input_variables=[\"message\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Configurando el modelo LLM\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "\n",
    "# Configurando la cadena de decisión\n",
    "cadena_final2 = prompt_final2 | llm | StrOutputParser()\n",
    "\n",
    "# Mensaje de prueba\n",
    "pregunta = \"\"\"\n",
    "            cual es la capital de colombia\n",
    "            \"\"\"\n",
    "\n",
    "# Ejecutando el modelo\n",
    "response = cadena_final2.invoke({\"message\": pregunta})\n",
    "\n",
    "# Imprimiendo el resultado\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
