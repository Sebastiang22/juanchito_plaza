{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langfuse in c:\\users\\sebas\\python\\lib\\site-packages (2.50.3)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.4.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (4.6.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (0.26.0)\n",
      "Requirement already satisfied: idna<4.0,>=3.7 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (3.10)\n",
      "Requirement already satisfied: packaging<25.0,>=23.2 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (2.5.2)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (1.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sebas\\python\\lib\\site-packages (from anyio<5.0.0,>=4.4.0->langfuse) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sebas\\python\\lib\\site-packages (from httpx<1.0,>=0.15.4->langfuse) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sebas\\python\\lib\\site-packages (from httpx<1.0,>=0.15.4->langfuse) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sebas\\python\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sebas\\python\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\sebas\\python\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\sebas\\python\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\sebas\\python\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: langgraph in c:\\users\\sebas\\python\\lib\\site-packages (0.2.19)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\sebas\\python\\lib\\site-packages (0.1.22)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\sebas\\python\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (3.9.4)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (0.2.39)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (0.2.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (0.1.117)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in c:\\users\\sebas\\python\\lib\\site-packages (from langgraph) (1.0.9)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain_openai) (1.42.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain_community) (0.6.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sebas\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sebas\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sebas\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sebas\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sebas\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sebas\\python\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\sebas\\python\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.26.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sebas\\python\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sebas\\python\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sebas\\python\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sebas\\python\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sebas\\python\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sebas\\python\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sebas\\python\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\sebas\\python\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.14.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sebas\\python\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sebas\\python\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sebas\\python\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sebas\\python\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sebas\\python\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\sebas\\python\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sebas\\python\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sebas\\python\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sebas\\python\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (2.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sebas\\python\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.40.0->langchain_openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sebas\\python\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install langfuse\n",
    "%pip install langchain langgraph langchain_openai langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-lf-d572a246-a761-447e-9adf-2cffce9b3083\n",
      "pk-lf-41aceb5f-9530-4eaf-aefb-63f279dc084f\n",
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    " # Carga las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "# get keys for your project from https://cloud.langfuse.com\n",
    "\n",
    "print(os.getenv(\"LANGFUSE_SECRET_KEY\"))\n",
    "print(os.getenv(\"LANGFUSE_PUBLIC_KEY\"))\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # for EU data region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # for US data region\n",
    " \n",
    "# your openai key\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))        # \"your-openai-api-key\"\n",
    "\n",
    "\n",
    "config = {\n",
    "    'user': 'root',\n",
    "    'password': 'password',\n",
    "    'host': 'localhost',\n",
    "    'port': 3308,\n",
    "    'database': 'juanchito_plaza'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objeto datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "\n",
    "class objeto_juancho_plaza(TypedDict):\n",
    "    # Primer nodo: decisi칩n sobre la funci칩n a realizar\n",
    "    celular: str  # N칰mero de tel칠fono del usuario\n",
    "    pregunta: str  # Pregunta original del usuario\n",
    "    decision: str  # Decisi칩n sobre qu칠 funci칩n ejecutar ('crear_usuario', 'consulta_sql', 'crear_pago')\n",
    "\n",
    "    # Nodos intermedios: detalles espec칤ficos para cada funci칩n\n",
    "    pedido: dict  # Contendr치 detalles de un nuevo usuario (nombre, email, etc.)\n",
    "    \n",
    "    # Nodo final: respuesta generada\n",
    "    respuesta: str  # Respuesta final del chatbot despu칠s de procesar la solicitud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'funcion': 'carta'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt_decision = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "    Eres un experto en gestionar operaciones de un sistema de pedidos de comida. Tienes tres funciones principales:\n",
    "    1. 'pedido': Usar esta funci칩n si la pregunta est치 relacionada platos del men칰, el nombre del cliente o la direccion.\n",
    "    2. 'confirmacion': Usar esta funci칩n si la pregunta est치 relacionada con confirmar un pedido o si la pregunta solo es si.\n",
    "    3. 'carta': Usar esta funci칩n si la pregunta est치 relacionada con consultar los platos o la carta del restaurante.\n",
    "\n",
    "    No necesitas ser estricto con las palabras clave, identifica el prop칩sito general de la pregunta para seleccionar la opci칩n adecuada. \n",
    "    Da una opci칩n binaria ('pedido', 'confirmacion','carta) basada en la pregunta. \n",
    "    Retorna un JSON con solo una clave 'funcion' sin pre치mbulo o explicaci칩n.\n",
    "\n",
    "    Pregunta a enrutar: {pregunta}\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"pregunta\"],\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "\n",
    "cadena_decision = prompt_decision | llm | JsonOutputParser()\n",
    "\n",
    "pregunta = \"carta\"\n",
    "print(cadena_decision.invoke({\"pregunta\": pregunta}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = \"\"\"\n",
    "**Men칰 a la carta:**\n",
    "1. **Churrasco + Chorizo** - $38.000\n",
    "    - 300 GRS. Sopas, Arroz, Jugo \n",
    "\n",
    "2. **Salm칩n** - $38.000\n",
    "    - 180 GRS. Sopa o crema, ensalada, Arroz, Jugo \n",
    "\n",
    "3. **Mojarra Frita** - $28.000\n",
    "    - 380 GRS. Sopa, Arroz, Jugo\n",
    "\n",
    "4. **Punta de anca de cerdo** - $27.000\n",
    "    - Sopas, Arroz, Jugo, ensalada\n",
    "\n",
    "5. **Filete de Trucha** - $20.000\n",
    "    - Sopas, Arroz, Jugo, ensalada\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def obtener_texto_imagen(image_path):\n",
    "  # Cargar la clave API desde las variables de entorno\n",
    "  api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "  # Getting the base64 string\n",
    "  base64_image = encode_image(image_path)\n",
    "\n",
    "  headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "  }\n",
    "\n",
    "  payload = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"dame los platos del menu ejecutivo de la imagen cada uno con su texto y precio, solo responde con el menu\"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "              \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"max_tokens\": 300\n",
    "  }\n",
    "\n",
    "  response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "  respuesta = response.json()\n",
    "\n",
    "  menu = respuesta['choices'][0]['message']['content']\n",
    "\n",
    "  return menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Men칰 Ejecutivo**\n",
      "\n",
      "1. **Sudado de Pollo** - $19.000  \n",
      "   * Pernil mixto en salsa criolla  \n",
      "   * Jugo del d칤a  \n",
      "   * Ensalada de la casa  \n",
      "   * Arroz blanco  \n",
      "   * Sopa de avena  \n",
      "\n",
      "2. **Filet Mignon** - $18.000  \n",
      "   * Res en salsa de tocinetas y champi침ones  \n",
      "   * Jugo natural del d칤a  \n",
      "   * Ensalada de la huerta  \n",
      "   * Sopa de avena  \n",
      "\n",
      "3. **Bandeja T칤pica con Chicharr칩n** - $25.000  \n",
      "   * Porci칩n de frijol + jugo + arroz blanco - ensalada y huevo frito  \n"
     ]
    }
   ],
   "source": [
    "image_path = \"C:/Users/sebas/chat-bot/juancho_plaza/chatbot/carta_juancho_plaza.jpg\"\n",
    "\n",
    "menu1 = obtener_texto_imagen(image_path)\n",
    "\n",
    "\n",
    "\n",
    "print(menu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    **Men칰 a la carta:**\n",
      "    1. **Churrasco + Chorizo** - $38.000\n",
      "    - 300 GRS. Sopas, Arroz, Jugo \n",
      "\n",
      "    2. **Salm칩n** - $38.000\n",
      "    - 180 GRS. Sopa o crema, ensalada, Arroz, Jugo \n",
      "\n",
      "    3. **Mojarra Frita** - $28.000\n",
      "    - 380 GRS. Sopa, Arroz, Jugo\n",
      "\n",
      "    4. **Punta de anca de cerdo** - $27.000\n",
      "    - Sopas, Arroz, Jugo, ensalada\n",
      "\n",
      "    5. **Filete de Trucha** - $20.000\n",
      "    - Sopas, Arroz, Jugo, ensalada\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Men칰 a la carta:**\n",
      "1. **Churrasco + Chorizo** - $38.000\n",
      "    - 300 GRS. Sopas, Arroz, Jugo \n",
      "\n",
      "2. **Salm칩n** - $38.000\n",
      "    - 180 GRS. Sopa o crema, ensalada, Arroz, Jugo \n",
      "\n",
      "3. **Mojarra Frita** - $28.000\n",
      "    - 380 GRS. Sopa, Arroz, Jugo\n",
      "\n",
      "4. **Punta de anca de cerdo** - $27.000\n",
      "    - Sopas, Arroz, Jugo, ensalada\n",
      "\n",
      "5. **Filete de Trucha** - $20.000\n",
      "    - Sopas, Arroz, Jugo, ensalada\n",
      "**Men칰 Ejecutivo**\n",
      "\n",
      "1. Sudado de Pollo - $19.000  \n",
      "   * Pernil mixto en salsa criolla  \n",
      "   * Jugo del d칤a  \n",
      "   * Ensalada de la casa  \n",
      "   * Arroz blanco  \n",
      "   * Sopa de avena  \n",
      "\n",
      "2. Filet Mignon - $18.000  \n",
      "   * Res en salsa de tocinetas y champi침ones  \n",
      "   * Jugo natural del d칤a  \n",
      "   * Ensalada de la huerta  \n",
      "   * Sopa de avena  \n",
      "\n",
      "3. Bandeja T칤pica con Chicharr칩n - $25.000  \n",
      "   * Porci칩n de frijol + Jugo + Arroz blanco - ensalada y huevo frito  \n"
     ]
    }
   ],
   "source": [
    "# Sumar (concatenar) los textos\n",
    "resultado = menu + menu1\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcion actualizar menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Funci칩n para guardar el men칰 en la base de datos\n",
    "def guardar_menu_en_db(menu_juanchito_plaza):\n",
    "    try:\n",
    "        # Configuraci칩n de conexi칩n a MySQL\n",
    "        connection = mysql.connector.connect(**config)\n",
    "        \n",
    "        if connection.is_connected():\n",
    "            cursor = connection.cursor()\n",
    "\n",
    "            # Inserci칩n del men칰 en la tabla 'menus' (solo contenido_menu)\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO menus (contenido_menu) \n",
    "                VALUES (%s)\n",
    "            \"\"\", (menu_juanchito_plaza,))  # Se pasa el par치metro como una tupla (notar la coma)\n",
    "\n",
    "            # Confirmar cambios\n",
    "            connection.commit()\n",
    "            print(\"Men칰 guardado exitosamente en la base de datos.\")\n",
    "\n",
    "    except Error as e:\n",
    "        print(f\"Error al guardar el men칰 en la base de datos: {e}\")\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "\n",
    "# Funci칩n para actualizar el men칰\n",
    "def actualizar_menu(imagen, numero, menu_carta):\n",
    "    # Obtener el texto de la imagen\n",
    "    menu_ejecutivo = obtener_texto_imagen(imagen)\n",
    "\n",
    "    # Combinar los men칰s\n",
    "    menu_juanchito_plaza = menu_carta + \" \" + menu_ejecutivo\n",
    "\n",
    "    # Verificar si el n칰mero es 321\n",
    "    if numero == 321:\n",
    "        # Guardar el men칰 combinado en la base de datos\n",
    "        guardar_menu_en_db(menu_juanchito_plaza)\n",
    "\n",
    "        return \"Menu actualizado\"\n",
    "    else:\n",
    "        print(\"N칰mero no v치lido. No se guard칩 el men칰.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Men칰 guardado exitosamente en la base de datos.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Menu actualizado'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "image_path = \"C:/Users/sebas/chat-bot/juancho_plaza/chatbot/carta_juancho_plaza.jpg\"  # Reemplazar con la ruta real\n",
    "numero = 321  # N칰mero a verificar\n",
    "\n",
    "# Actualizar el men칰\n",
    "respuesta =actualizar_menu(image_path, numero, menu)\n",
    "respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n**Men칰 a la carta:**\\n1. **Churrasco + Chorizo** - $38.000\\n    - 300 GRS. Sopas, Arroz, Jugo \\n\\n2. **Salm칩n** - $38.000\\n    - 180 GRS. Sopa o crema, ensalada, Arroz, Jugo \\n\\n3. **Mojarra Frita** - $28.000\\n    - 380 GRS. Sopa, Arroz, Jugo\\n\\n4. **Punta de anca de cerdo** - $27.000\\n    - Sopas, Arroz, Jugo, ensalada\\n\\n5. **Filete de Trucha** - $20.000\\n    - Sopas, Arroz, Jugo, ensalada\\n'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena_pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'correct', 'structured_order': {'name': 'sebastian gomez', 'address': 'calle 12 # 4-01', 'dishes': [{'dish': 'salm칩n', 'quantity': 2, 'extras': []}, {'dish': 'churrasco', 'quantity': 1, 'extras': []}]}, 'unavailable_dishes': [], 'error_message': ''}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    " \n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_pedidos2 = PromptTemplate(\n",
    "    template=\"\"\"  \n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "    The restaurant Juanchito Plazo needs to verify if the following message from a customer contains all the required information to place a delivery order. \n",
    "    The order must include the following:\n",
    "    1. The customer's name.\n",
    "    2. The delivery address.\n",
    "    3. The dishes they want to order (verified against the provided menu).\n",
    "\n",
    "    The current menu is: {menu}\n",
    "\n",
    "    Verify the following:\n",
    "    - The requested dishes are available in the menu provided. If any dish is not on the menu, mark it as incorrect and list the unavailable dishes.\n",
    "    - Accept dish names regardless of capitalization or accentuation. For example, \"Salm칩n\", \"salmon\", \"SALM칍N\", or \"salm칩n\" should all be considered valid and equal.\n",
    "\n",
    "    Convert any quantities written in words to numbers for the JSON response. \n",
    "\n",
    "    Respond in JSON format with the following keys:\n",
    "    - \"status\": \"correct\" or \"incorrect\" depending on whether all the required information is present and the dishes are valid.\n",
    "    - \"structured_order\": If the order is correct, return an object with the structure:\n",
    "      - \"name\": customer's name,\n",
    "      - \"address\": delivery address,\n",
    "      - \"dishes\": list of objects containing:\n",
    "        - \"dish\": name of the dish from the menu,\n",
    "        - \"quantity\": quantity requested (in numbers),\n",
    "        - \"extras\": optional list of extras or notes (e.g., \"sin cebolla\").\n",
    "    - \"unavailable_dishes\": If any dishes are not available in the menu, return a list with the names of those dishes.\n",
    "    - \"error_message\": If the order is incorrect, explain the reason.\n",
    "\n",
    "    Here is the customer's message:\n",
    "    {pregunta}\n",
    "    \"\"\",\n",
    "    input_variables=[\"menu\", \"pregunta\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "\n",
    "cadena_pedidos = prompt_pedidos2 | llm | JsonOutputParser()\n",
    "\n",
    "pregunta= \"\"\"sebastian gomez\n",
    "             calle 12 # 4-01\n",
    "             dos salmon, un churrasco\n",
    "            \"\"\"\n",
    "# Ejemplo de uso\n",
    "inputs = {\n",
    "    \"pregunta\": pregunta,\n",
    "    \"menu\": menu\n",
    "}\n",
    "\n",
    "respuesta_pedidos = cadena_pedidos.invoke(inputs)\n",
    "print(respuesta_pedidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: correct\n",
      "Name: sebastian gomez\n",
      "Address: calle 12 # 4-01\n",
      "Dish: salm칩n\n",
      "Quantity: 2\n",
      "Extras: []\n",
      "Dish: churrasco\n",
      "Quantity: 1\n",
      "Extras: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Acceder a los datos\n",
    "print(\"Status:\", respuesta_pedidos['status'])\n",
    "print(\"Name:\", respuesta_pedidos['structured_order']['name'])\n",
    "print(\"Address:\", respuesta_pedidos['structured_order']['address'])\n",
    "\n",
    "# Acceder a la lista de platos\n",
    "for dish in respuesta_pedidos['structured_order']['dishes']:\n",
    "    print(\"Dish:\", dish['dish'])\n",
    "    print(\"Quantity:\", dish['quantity'])\n",
    "    print(\"Extras:\", dish['extras'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"dish\": \"salm칩n\",\n",
      "        \"quantity\": 2,\n",
      "        \"extras\": []\n",
      "    },\n",
      "    {\n",
      "        \"dish\": \"churrasco\",\n",
      "        \"quantity\": 1,\n",
      "        \"extras\": []\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Acceder a la lista de platos\n",
    "platos = []\n",
    "for dish in respuesta_pedidos['structured_order']['dishes']:\n",
    "    plato_info = {\n",
    "        \"dish\": dish['dish'],\n",
    "        \"quantity\": dish['quantity'],\n",
    "        \"extras\": dish['extras']\n",
    "    }\n",
    "    platos.append(plato_info)\n",
    "\n",
    "# Convertir la lista de platos en JSON\n",
    "platos_json = json.dumps(platos, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Imprimir el JSON\n",
    "print(platos_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena pedido final2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola Sebasti치n G칩mez,\\n\\nGracias por tu pedido. Sin embargo, lamento informarte que las pizzas no est치n disponibles en nuestro men칰 actual. Te invito a elegir entre los siguientes platos:\\n\\n1. **Churrasco + Chorizo** - $38.000\\n2. **Salm칩n** - $38.000\\n3. **Mojarra Frita** - $28.000\\n4. **Punta de anca de cerdo** - $27.000\\n5. **Filete de Trucha** - $20.000\\n\\nPor favor, h치zmelo saber qu칠 plato te gustar칤a ordenar. 춰Espero tu respuesta!'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    " \n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Creando el template del prompt\n",
    "prompt_pedidos_final2 = PromptTemplate(\n",
    "    template=\"\"\" \n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are the order-taking assistant for Juancho Plaza, a restaurant. The customer has sent a message with details of their order. Your task is to review the message, check if all the necessary information is provided, and if the dishes requested are available on the menu. Based on this, generate an appropriate response in Spanish. \n",
    "\n",
    "    Here are the steps:\n",
    "    \n",
    "    1. If the customer's message includes all the necessary information, such as their **name**, and **dishes to order**, proceed to confirm the order.\n",
    "    2. If **any information is missing** (name or address), generate a polite response asking for the missing information. Mention which specific detail is missing.\n",
    "    3. If the customer orders dishes that are **not available on the menu** ({menu}), kindly inform them that the following dishes are not available and suggest they choose from the available menu items.\n",
    "    \n",
    "    Menu for today: {menu}\n",
    "\n",
    "    Customer message: {pregunta}\n",
    "\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"menu\", \"pregunta\"]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "\n",
    "cadena_pedidos = prompt_pedidos2 | llm | StrOutputParser()\n",
    "\n",
    "pregunta= \"\"\"sebastian gomez\n",
    "             calle 12 # 4-01\n",
    "             dos pizzas\n",
    "            \"\"\"\n",
    "# Ejemplo de uso\n",
    "inputs = {\n",
    "    \"pregunta\": pregunta,\n",
    "    \"menu\": menu\n",
    "}\n",
    "\n",
    "respuesta_pedidos = cadena_pedidos.invoke(inputs)\n",
    "respuesta_pedidos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funciones nodo pedidos 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardar_pedido_db(nombre_cliente, celular, direccion_cliente, pedido_final_json):\n",
    "    try:\n",
    "        # Conectar a la base de datos\n",
    "        connection = mysql.connector.connect(**config)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Verificar si el cliente ya existe\n",
    "        query_check_celular = \"SELECT id, nombre FROM clientes WHERE telefono = %s\"\n",
    "        cursor.execute(query_check_celular, (celular,))\n",
    "        cliente = cursor.fetchone()\n",
    "\n",
    "        if cliente:\n",
    "            cliente_id, nombre_existente = cliente\n",
    "            print(f\"Cliente encontrado: {cliente}\")\n",
    "            # Actualizar nombre del cliente si es diferente\n",
    "            if nombre_existente != nombre_cliente:\n",
    "                print(f\"Actualizando el nombre del cliente con n칰mero {celular}.\")\n",
    "                cursor.execute(\"UPDATE clientes SET nombre = %s WHERE id = %s\", (nombre_cliente, cliente_id))\n",
    "                connection.commit()\n",
    "        else:\n",
    "            # Si el cliente no existe, crear un nuevo cliente\n",
    "            print(\"Cliente no encontrado. Creando nuevo cliente.\")\n",
    "            query_insert_cliente = \"\"\"\n",
    "                INSERT INTO clientes (nombre, telefono) \n",
    "                VALUES (%s, %s)\n",
    "            \"\"\"\n",
    "            cursor.execute(query_insert_cliente, (nombre_cliente, celular))\n",
    "            connection.commit()\n",
    "            cliente_id = cursor.lastrowid  # Obtener el ID del nuevo cliente\n",
    "            print(f\"Nuevo cliente creado con ID {cliente_id}.\")\n",
    "\n",
    "        # Guardar el pedido en la tabla pedidos\n",
    "        query_insert_pedido = \"\"\"\n",
    "            INSERT INTO pedidos (cliente_id, pedido_json, direccion, pedido_cofirmado) \n",
    "            VALUES (%s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        # Aqu칤 asumimos que la confirmaci칩n inicial es False\n",
    "        confirmacion_pedido = False  # Por defecto, el pedido no est치 confirmado\n",
    "        cursor.execute(query_insert_pedido, (cliente_id, pedido_final_json, direccion_cliente, confirmacion_pedido))\n",
    "        connection.commit()\n",
    "\n",
    "        print(f\"Pedido guardado para el cliente con ID {cliente_id}\")\n",
    "\n",
    "    except mysql.connector.Error as e:\n",
    "        print(f\"Error al interactuar con la base de datos: {e}\")\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"Conexi칩n a MySQL cerrada.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nodo pedido 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente encontrado: (3, 'sebastian gomez')\n",
      "Pedido guardado para el cliente con ID 3\n",
      "Conexi칩n a MySQL cerrada.\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que 'menu' est치 definido anteriormente\n",
    "pregunta = \"\"\"sebastian gomez\n",
    "             calle 12 # 4-01\n",
    "             dos salmon\n",
    "            \"\"\"\n",
    "\n",
    "# Ejemplo de uso\n",
    "inputs = {\n",
    "    \"pregunta\": pregunta,\n",
    "    \"menu\": menu\n",
    "}\n",
    "\n",
    "# Procesar la pregunta utilizando el prompt y el modelo LLM\n",
    "cadena_pedidos2 = prompt_pedidos2 | llm | JsonOutputParser()\n",
    "respuesta_pedidos = cadena_pedidos2.invoke(inputs)\n",
    "\n",
    "celular = \"321\"\n",
    "estado_pedido = respuesta_pedidos['status']\n",
    "# Verificar si la respuesta contiene los datos necesarios\n",
    "if estado_pedido == \"correct\":\n",
    "    # Acceder a los datos\n",
    "    nombre_cliente = respuesta_pedidos['structured_order']['name']\n",
    "    direccion_cliente = respuesta_pedidos['structured_order']['address']\n",
    "\n",
    "    # Acceder a la lista de platos\n",
    "    platos = []\n",
    "    for dish in respuesta_pedidos['structured_order']['dishes']:\n",
    "        plato_info = {\n",
    "            \"dish\": dish['dish'],\n",
    "            \"quantity\": dish['quantity'],\n",
    "            \"extras\": dish['extras']\n",
    "        }\n",
    "        platos.append(plato_info)\n",
    "\n",
    "    # Convertir la lista de platos en JSON\n",
    "    platos_json = json.dumps(platos, ensure_ascii=False, indent=4)\n",
    "\n",
    "    \n",
    "    # Guardar el pedido en la base de datos\n",
    "    guardar_pedido_db(nombre_cliente, celular, direccion_cliente, platos_json)\n",
    "else:\n",
    "    print(\"El pedido no es v치lido:\", respuesta_pedidos['error_message'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n    \"status\": \"correct\",\\n    \"structured_order\": {\\n        \"name\": \"sebastian gomez\",\\n        \"address\": \"calle 12 # 4-01\",\\n        \"dishes\": [\\n            {\\n                \"dish\": \"Salm칩n\",\\n                \"quantity\": 2,\\n                \"extras\": []\\n            }\\n        ]\\n    },\\n    \"unavailable_dishes\": [],\\n    \"error_message\": \"\"\\n}\\n```'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuesta_pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[192], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convertir la cadena JSON a un diccionario\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m respuesta_pedidos \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrespuesta_pedidos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Acceder a los datos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m status \u001b[38;5;241m=\u001b[39m respuesta_pedidos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sebas\\python\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\sebas\\python\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\sebas\\python\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Convertir la cadena JSON a un diccionario\n",
    "respuesta_pedidos = json.loads(respuesta_pedidos)\n",
    "\n",
    "# Acceder a los datos\n",
    "status = respuesta_pedidos['status']\n",
    "nombre_cliente = respuesta_pedidos['structured_order']['name']\n",
    "direccion_cliente = respuesta_pedidos['structured_order']['address']\n",
    "dishes = respuesta_pedidos['structured_order']['dishes']\n",
    "\n",
    "# Imprimir los datos\n",
    "if status == \"correct\":\n",
    "    print(\"Estado del pedido:\", status)\n",
    "    print(\"Nombre del Cliente:\", nombre_cliente)\n",
    "    print(\"Direcci칩n del Cliente:\", direccion_cliente)\n",
    "    print(\"Pedido:\")\n",
    "    for dish in dishes:\n",
    "        print(f\" - Plato: {dish['dish']}, Cantidad: {dish['quantity']}, Extras: {dish['extras']}\")\n",
    "else:\n",
    "    print(\"El pedido es incorrecto.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena final 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La capital de Colombia es Bogot치. 游땕 Soy el chatbot de Juancho Plaza y puedo ayudarte con tu pedido. Ofrecemos entregas solo en la *Zona Industrial Malter칤a*, desde *Bosque Popular* hasta *Onc칩logos*. Tomamos pedidos hasta las *11 a.m*. Por favor, proporciona tu nombre, direcci칩n y los platos del men칰 que te gustar칤a pedir.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Creando el template del prompt\n",
    "prompt_final2 = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    message: {message} \n",
    "\n",
    "    You are Juancho Plaza's order-taking chatbot. If the message contains a greeting (such as \"hola\", \"buenos dias\", \"buenas tardes\"), respond with the following:\n",
    "    \n",
    "    游땕 Hello! I am Juancho Plaza's chatbot, and I can help you with your order. We offer deliveries only in the *Malter칤a Industrial Zone*, from *Bosque Popular* to *Onc칩logos*. We take orders until *11 a.m*. Please provide your name, address, and the dishes from the menu that you would like to order.\n",
    "\n",
    "    If the message contains a question about delivery times, respond by saying: \"We take orders until *11 a.m*.\"\n",
    "\n",
    "    If the message contains a question about delivery areas, respond by saying: \"We offer deliveries only in the *Malter칤a Industrial Zone*, from *Bosque Popular* to *Onc칩logos*.\"\n",
    "\n",
    "    If the message does not contain a greeting, first respond to the customer's message and then provide the following order-taking information:\n",
    "\n",
    "    Personalized response to the customer's message, 游땕 I am Juancho Plaza's chatbot, I can help you with your order.\n",
    "\n",
    "    Generate the resonse pin Spanish.\n",
    "    Response:\n",
    "    \"\"\",\n",
    "    input_variables=[\"message\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Configurando el modelo LLM\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "\n",
    "# Configurando la cadena de decisi칩n\n",
    "cadena_final2 = prompt_final2 | llm | StrOutputParser()\n",
    "\n",
    "# Mensaje de prueba\n",
    "pregunta = \"\"\"\n",
    "            cual es la capital de colombia\n",
    "            \"\"\"\n",
    "\n",
    "# Ejecutando el modelo\n",
    "response = cadena_final2.invoke({\"message\": pregunta})\n",
    "\n",
    "# Imprimiendo el resultado\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
