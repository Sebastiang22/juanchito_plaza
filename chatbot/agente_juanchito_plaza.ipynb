{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langfuse\n",
      "  Downloading langfuse-2.50.3-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting anyio<5.0.0,>=4.4.0 (from langfuse)\n",
      "  Downloading anyio-4.6.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting backoff>=1.10.0 (from langfuse)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (0.26.0)\n",
      "Collecting idna<4.0,>=3.7 (from langfuse)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging<25.0,>=23.2 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in c:\\users\\sebas\\python\\lib\\site-packages (from langfuse) (2.5.2)\n",
      "Collecting wrapt<2.0,>=1.14 (from langfuse)\n",
      "  Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sebas\\python\\lib\\site-packages (from anyio<5.0.0,>=4.4.0->langfuse) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sebas\\python\\lib\\site-packages (from httpx<1.0,>=0.15.4->langfuse) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sebas\\python\\lib\\site-packages (from httpx<1.0,>=0.15.4->langfuse) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sebas\\python\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sebas\\python\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\sebas\\python\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\sebas\\python\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse) (4.12.2)\n",
      "Downloading langfuse-2.50.3-py3-none-any.whl (213 kB)\n",
      "Downloading anyio-4.6.0-py3-none-any.whl (89 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Installing collected packages: wrapt, idna, backoff, anyio, langfuse\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 3.7.1\n",
      "    Uninstalling anyio-3.7.1:\n",
      "      Successfully uninstalled anyio-3.7.1\n",
      "Successfully installed anyio-4.6.0 backoff-2.2.1 idna-3.10 langfuse-2.50.3 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastapi 0.104.1 requires anyio<4.0.0,>=3.7.1, but you have anyio 4.6.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\sebas\\python\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: langgraph in c:\\users\\sebas\\python\\lib\\site-packages (0.2.19)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\sebas\\python\\lib\\site-packages (0.1.22)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\sebas\\python\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (3.9.4)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (0.2.39)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (0.2.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (0.1.117)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in c:\\users\\sebas\\python\\lib\\site-packages (from langgraph) (1.0.9)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain_openai) (1.42.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain_community) (0.6.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sebas\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sebas\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sebas\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sebas\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sebas\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sebas\\python\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\sebas\\python\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\sebas\\python\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sebas\\python\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.26.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sebas\\python\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sebas\\python\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sebas\\python\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sebas\\python\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sebas\\python\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sebas\\python\\lib\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sebas\\python\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\sebas\\python\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.14.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sebas\\python\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sebas\\python\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sebas\\python\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sebas\\python\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sebas\\python\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\sebas\\python\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sebas\\python\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sebas\\python\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sebas\\python\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (2.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sebas\\python\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.40.0->langchain_openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sebas\\python\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\sebas\\python\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install langfuse\n",
    "%pip install langchain langgraph langchain_openai langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-lf-d572a246-a761-447e-9adf-2cffce9b3083\n",
      "pk-lf-41aceb5f-9530-4eaf-aefb-63f279dc084f\n",
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    " # Carga las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "# get keys for your project from https://cloud.langfuse.com\n",
    "\n",
    "print(os.getenv(\"LANGFUSE_SECRET_KEY\"))\n",
    "print(os.getenv(\"LANGFUSE_PUBLIC_KEY\"))\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # for EU data region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # for US data region\n",
    " \n",
    "# your openai key\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))        # \"your-openai-api-key\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse(\n",
    "  secret_key=\"sk-lf-4422f9eb-72b2-4009-8537-975913a3356a\",\n",
    "  public_key=\"pk-lf-9bcae528-473d-4739-8f83-9d94930fac2d\",\n",
    "  host=\"https://us.cloud.langfuse.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chatbot': {'messages': [AIMessage(content='Langfuse is a tool designed to help developers monitor and observe their applications that utilize Large Language Models (LLMs). It provides capabilities for logging, visualizing, and debugging LLM calls, which can be crucial for understanding how these models are being used and how they perform in real-world applications. Langfuse supports various LLM frameworks and can be integrated with popular logging and monitoring tools like OpenTelemetry. This makes it easier for developers to track the performance and behavior of their LLM-powered applications, identify issues, and optimize their usage.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 13, 'total_tokens': 122, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_52a7f40b0b', 'finish_reason': 'stop', 'logprobs': None}, id='run-d0b79821-024e-430a-8afd-fe2881a809d8-0', usage_metadata={'input_tokens': 13, 'output_tokens': 109, 'total_tokens': 122})]}}\n"
     ]
    }
   ],
   "source": [
    " \n",
    "from langfuse.callback import CallbackHandler\n",
    "langfuse_handler = CallbackHandler(\n",
    "    public_key=\"pk-lf-4a3f0787-2834-4e4c-8b4e-ad0613546467\",\n",
    "    secret_key=\"sk-lf-cadc4cf3-9442-4100-8adb-e28aefd65de5\",\n",
    "    host=\"https://us.cloud.langfuse.com\"\n",
    ")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def obtener_texto_imagen(image_path):\n",
    "  # Cargar la clave API desde las variables de entorno\n",
    "  api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "  # Getting the base64 string\n",
    "  base64_image = encode_image(image_path)\n",
    "\n",
    "  headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "  }\n",
    "\n",
    "  payload = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"dame el texto de la imagen\"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "              \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"max_tokens\": 300\n",
    "  }\n",
    "\n",
    "  response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "  respuesta = response.json()\n",
    "\n",
    "  menu = respuesta['choices'][0]['message']['content']\n",
    "\n",
    "  return menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aquí tienes el texto de la imagen:\\n\\n---\\n\\n**JuanChito Plaza**\\n\\n**MENÚ A LA CARTA**\\n\\n**Churrasco + Chorizo**  $38.000\\n300 GRS. Sopa - Arroz - Jugo\\n\\n**Salmón**  $38.000\\n180 GRS. Sopa o crema - Ensalada, Arroz - Jugo\\n\\n**Mojarra Frita**  $28.000\\n380 GRS. Sopa - Arroz - Jugo\\n\\n**Punta de anca de cerdo**  $27.000\\nSopa - Arroz - Jugo - Ensalada\\n\\n**Filete de trucha**  $20.000\\nSopa - Arroz - Jugo - Ensalada\\n\\n---\\n\\n**MENÚ Ejecutivo**\\n\\n**Sudado de pollo**  $19.000\\n* Pernil mixto en salsa criolla\\n* Jugo del día\\n* Ensalada de la casa\\n* Arroz blanco\\n* Sopa de avena\\n\\n**Filet Mignon**  $18.000\\n* Res en salsa de tocineta y champiñones\\n* Jugo natural del día\\n* Ensalada de la huerta\\n* Sopa de avena\\n\\n**Bandeja típica con chicharron**  $25.000\\n* Porción de frijol + jugo + arroz blanco - ensalada y huevo f'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"C:/Users/sebas/chat-bot/juancho_plaza/chatbot/carta_juancho_plaza.jpg\"\n",
    "\n",
    "menu = obtener_texto_imagen(image_path)\n",
    "print(menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aquí tienes el texto de la imagen:\n",
      "\n",
      "---\n",
      "\n",
      "**JuanChito Plaza**\n",
      "\n",
      "**MENÚ A LA CARTA**\n",
      "\n",
      "**Churrasco + Chorizo**  $38.000\n",
      "300 GRS. Sopa - Arroz - Jugo\n",
      "\n",
      "**Salmón**  $38.000\n",
      "180 GRS. Sopa o crema - Ensalada, Arroz - Jugo\n",
      "\n",
      "**Mojarra Frita**  $28.000\n",
      "380 GRS. Sopa - Arroz - Jugo\n",
      "\n",
      "**Punta de anca de cerdo**  $27.000\n",
      "Sopa - Arroz - Jugo - Ensalada\n",
      "\n",
      "**Filete de trucha**  $20.000\n",
      "Sopa - Arroz - Jugo - Ensalada\n",
      "\n",
      "---\n",
      "\n",
      "**MENÚ Ejecutivo**\n",
      "\n",
      "**Sudado de pollo**  $19.000\n",
      "* Pernil mixto en salsa criolla\n",
      "* Jugo del día\n",
      "* Ensalada de la casa\n",
      "* Arroz blanco\n",
      "* Sopa de avena\n",
      "\n",
      "**Filet Mignon**  $18.000\n",
      "* Res en salsa de tocineta y champiñones\n",
      "* Jugo natural del día\n",
      "* Ensalada de la huerta\n",
      "* Sopa de avena\n",
      "\n",
      "**Bandeja típica con chicharron**  $25.000\n",
      "* Porción de frijol + jugo + arroz blanco - ensalada y huevo f\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-ABWSBrAiKFo54yEYoDpQE2ePphwlU',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1727309723,\n",
       " 'model': 'gpt-4o-2024-05-13',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'Claro, aquí está el texto de la imagen:\\n\\n---\\n\\n**Menú A LA CARTA**\\n\\n**Churrasco + Chorizo $38.000**\\n300 GRS. Sopa - Arroz - Jugo\\n\\n**Salmón $38.000**\\n180 GRS. Sopa o crema - Ensalada - Arroz - Jugo\\n\\n**Mojarra Frita $28.000**\\n380 GRS. Sopa - Arroz - Jugo\\n\\n**Punta de anca de cerdo $27.000**\\nSopa - Arroz - Jugo - Ensalada\\n\\n**Filete de trucha $20.000**\\nSopa - Arroz - Jugo - Ensalada\\n\\n**WhatsApp:**\\n3146905954\\n3148641523\\n\\n---\\n\\n**Menú Ejecutivo**\\n\\n**Spaghettis Sicilianos $19.000**\\n- Pollo en trozos en salsa bechamel\\n- Jugo del día\\n- Ensalada de la casa\\n- Pan - Sopa de plátano\\n\\n**Cerdo al wok $18.000**\\n- Cerdo en julianas + vegetales salteados\\n- Jugo natural del día\\n- Ensalada de la huerta\\n- Sopa de plátano\\n\\n**Bandeja típica con chicharrón $25.000**\\n- Porción de frijol\\n- Jugo\\n- Arroz blanco\\n- En',\n",
       "    'refusal': None},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'length'}],\n",
       " 'usage': {'prompt_tokens': 1119,\n",
       "  'completion_tokens': 300,\n",
       "  'total_tokens': 1419,\n",
       "  'completion_tokens_details': {'reasoning_tokens': 0}},\n",
       " 'system_fingerprint': 'fp_3537616b13'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuesta = response.json()\n",
    "respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claro, aquí está el texto de la imagen:\n",
      "\n",
      "---\n",
      "\n",
      "**Menú A LA CARTA**\n",
      "\n",
      "**Churrasco + Chorizo $38.000**\n",
      "300 GRS. Sopa - Arroz - Jugo\n",
      "\n",
      "**Salmón $38.000**\n",
      "180 GRS. Sopa o crema - Ensalada - Arroz - Jugo\n",
      "\n",
      "**Mojarra Frita $28.000**\n",
      "380 GRS. Sopa - Arroz - Jugo\n",
      "\n",
      "**Punta de anca de cerdo $27.000**\n",
      "Sopa - Arroz - Jugo - Ensalada\n",
      "\n",
      "**Filete de trucha $20.000**\n",
      "Sopa - Arroz - Jugo - Ensalada\n",
      "\n",
      "**WhatsApp:**\n",
      "3146905954\n",
      "3148641523\n",
      "\n",
      "---\n",
      "\n",
      "**Menú Ejecutivo**\n",
      "\n",
      "**Spaghettis Sicilianos $19.000**\n",
      "- Pollo en trozos en salsa bechamel\n",
      "- Jugo del día\n",
      "- Ensalada de la casa\n",
      "- Pan - Sopa de plátano\n",
      "\n",
      "**Cerdo al wok $18.000**\n",
      "- Cerdo en julianas + vegetales salteados\n",
      "- Jugo natural del día\n",
      "- Ensalada de la huerta\n",
      "- Sopa de plátano\n",
      "\n",
      "**Bandeja típica con chicharrón $25.000**\n",
      "- Porción de frijol\n",
      "- Jugo\n",
      "- Arroz blanco\n",
      "- En\n"
     ]
    }
   ],
   "source": [
    "print(respuesta['choices'][0]['message']['content'])\n",
    "menu = respuesta['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aquí tienes el texto de la carta del restaurante Juancho Plaza:\\n\\n**Menú a la carta:**\\n- Churrasco + Chorizo $38,000\\n  - 300 GRs. Sopa - Arroz - Jugo\\n- Salmón $38,000\\n  - 180 GRs. Sopa o crema - Ensalada - Arroz - Jugo\\n- Mojarra Frita $28,000\\n  - 380 GRs. Sopa - Arroz - Jugo\\n- Punta de anca de cerdo $27,000\\n  - Sopa - Arroz - Jugo - Ensalada\\n- Filete de trucha $20,000\\n  - Sopa - Arroz - Jugo - Ensalada\\n\\n**Menú Ejecutivo:**\\n- Spaghettis Sicilianos $19,000\\n  - Pollo en trozos en salsa bechamel\\n  - Jugo del día\\n  - Ensalada de la casa\\n  - Pan + sopa de plátano\\n- Cerdo al Wok $18,000\\n  - Cerdo en julianas + vegetales salteados\\n  - Jugo natural del día\\n  - Ensalada de la huerta\\n  - Sopa de plátano\\n- bandeja típica con chicharrón $25,000\\n  - Porción de frijol + Jugo + Arroz'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menu \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cadena_pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "def modelo_pedidos(messages: str):\n",
    "    prompt_pedidos = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        <|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "        Eres un experto en gestionar pedidos para el restaurante 'Juancho Plaza'. Tu tarea principal es recibir el pedido de los clientes y estructurarlo correctamente basándote en el menú del restaurante, el cual está dividido en dos secciones: \"A la carta\" y \"Menú ejecutivo\". El menú es el siguiente:\n",
    "\n",
    "        Menu:\n",
    "        {menu}\n",
    "\n",
    "        Tu deber es:\n",
    "        1. Recibir el pedido del cliente en lenguaje natural.\n",
    "        2. Identificar los elementos del pedido basándote en las opciones disponibles en el menú.\n",
    "        3. Estructurar el pedido en un formato JSON con las claves:\n",
    "        - 'a_la_carta' (una lista de los productos pedidos de la sección \"A la carta\").\n",
    "        - 'menu_ejecutivo' (una lista de los productos pedidos de la sección \"Menú ejecutivo\").\n",
    "        - 'extras' (una lista de extras o especificaciones adicionales si las hay).\n",
    "\n",
    "        Solo responde con el JSON del pedido, sin agregar ninguna explicación adicional. Si el cliente menciona algo que no está en el menú, ignóralo.\n",
    "\n",
    "        Pedido del cliente: {messages}\n",
    "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "        input_variables=[\"menu\", \"messages\"],\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini')\n",
    "\n",
    "    cadena_pedidos = prompt_pedidos | llm | JsonOutputParser()\n",
    "\n",
    "    menu = \"\"\"\"\n",
    "    Aquí tienes el texto de la carta del restaurante Juancho Plaza:\n",
    "\n",
    "    **Menú a la carta:**\n",
    "    - Churrasco + Chorizo $38,000\n",
    "    - 300 GRs. Sopa - Arroz - Jugo\n",
    "    - Salmón $38,000\n",
    "    - 180 GRs. Sopa o crema - Ensalada - Arroz - Jugo\n",
    "    - Mojarra Frita $28,000\n",
    "    - 380 GRs. Sopa - Arroz - Jugo\n",
    "    - Punta de anca de cerdo $27,000\n",
    "    - Sopa - Arroz - Jugo - Ensalada\n",
    "    - Filete de trucha $20,000\n",
    "    - Sopa - Arroz - Jugo - Ensalada\n",
    "\n",
    "    **Menú Ejecutivo:**\n",
    "    - Spaghettis Sicilianos $19,000\n",
    "    - Pollo en trozos en salsa bechamel\n",
    "    - Jugo del día\n",
    "    - Ensalada de la casa\n",
    "    - Pan + sopa de plátano\n",
    "    - Cerdo al Wok $18,000\n",
    "    - Cerdo en julianas + vegetales salteados\n",
    "    - Jugo natural del día\n",
    "    - Ensalada de la huerta\n",
    "    - Sopa de plátano\n",
    "    - bandeja típica con chicharrón $25,000\n",
    "    - Porción de frijol + Jugo + Arroz\n",
    "        \"\"\"\n",
    "\n",
    "    # Invocando el modelo\n",
    "    response = cadena_pedidos.invoke({\n",
    "        \"messages\": messages,\n",
    "        \"menu\": menu\n",
    "    })\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "herramienta pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_la_carta': [], 'menu_ejecutivo': [], 'extras': []}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "# Definir el esquema de entrada utilizando pydantic\n",
    "class PedidoInput(BaseModel):\n",
    "    messages: str\n",
    "\n",
    "# Crear la herramienta utilizando StructuredTool y el esquema de entrada\n",
    "pedidos_tool = StructuredTool(\n",
    "    name=\"pedidos\",\n",
    "    func=modelo_pedidos,\n",
    "    description=\"Procesa el pedido de un cliente basado en el menú del restaurante Juancho Plaza\",\n",
    "    args_schema=PedidoInput  # Utilizamos el esquema Pydantic\n",
    ")\n",
    "# Ahora, puedes usar `pedidos_tool` para procesar los pedidos\n",
    "response = pedidos_tool.invoke({\"messages\": \"hola\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agente supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.tools import StructuredTool\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Definir los miembros del equipo\n",
    "members = [\"pedidos\"]\n",
    "\n",
    "# Definir el prompt del sistema\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following worker: {members}. The worker can process the customer's\"\n",
    "    \" order using a menu and return the order details. Once the user\"\n",
    "    \" confirms the order, respond with FINISH.\"\n",
    ")\n",
    "\n",
    "# Opciones de respuesta: continuar con la herramienta o finalizar\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "# Definir el schema de la función para seleccionar el siguiente paso\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role or FINISH if the user confirms the order.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"next\": {\n",
    "                \"title\": \"Next\",\n",
    "                \"anyOf\": [\n",
    "                    {\"enum\": options},\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Crear el prompt utilizando ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, should we proceed with the order using pedidos or FINISH?\"\n",
    "            \" Select one of: {options}.\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "# Crear la cadena de supervisor\n",
    "supervisor_chain = (\n",
    "    prompt\n",
    "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "    | JsonOutputFunctionsParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utilidades auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    " \n",
    "def create_agent(llm: ChatOpenAI, system_prompt: str, tools: list):\n",
    "    # Each worker node will be given a name and some tools.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    " \n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "from typing import Sequence, TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "import json\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    " \n",
    "# Add the time agent using the create_agent helper function\n",
    "agente_pedido = create_agent(llm, \"Procesa el pedido de un cliente basado en el menú del restaurante Juancho Plaza\", [pedidos_tool])\n",
    "pedido_nodo = functools.partial(agent_node, agent=agente_pedido, name = \"pedidos\")\n",
    " \n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    " \n",
    "# Add a \"chatbot\" node. Nodes represent units of work. They are typically regular python functions.\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)\n",
    "workflow.add_node(\"pedidos\", pedidos_tool)  # Agregar la herramienta pedidos_tool\n",
    " \n",
    "# We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    " \n",
    "# Conditional edges usually contain \"if\" statements to route to different nodes depending on the current graph state.\n",
    "# These functions receive the current graph state and return a string or list of strings indicating which node(s) to call next.\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    " \n",
    "# Add an entry point. This tells our graph where to start its work each time we run it.\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    " \n",
    "# To be able to run our graph, call \"compile()\" on the graph builder. This creates a \"CompiledGraph\" we can use invoke on our state.\n",
    "graph_2 = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Graph' from 'langgraph' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Graph\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpregel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangfuse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CallbackHandler\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Graph' from 'langgraph' (unknown location)"
     ]
    }
   ],
   "source": [
    "from langgraph import Graph\n",
    "from langgraph.pregel import HumanMessage\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# Initialize your graph (ensure it's defined somewhere)\n",
    "graph_2 = Graph()  # Replace with your actual graph initialization\n",
    "\n",
    "# Initialize Langfuse CallbackHandler for Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# Create a HumanMessage\n",
    "human_message = HumanMessage(content=\"How does photosynthesis work?\")\n",
    "\n",
    "# Stream with the correct input format\n",
    "for s in graph_2.stream({\"messages\": [human_message.content]},  # Wrap the string in a list\n",
    "                        config={\"callbacks\": [langfuse_handler]}):\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph_2.get_graph().draw_mermaid_png()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
